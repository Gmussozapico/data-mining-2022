# Pregunta 2

## Para cada idioma, ¬øsomos capaces de ajustar un modelo predictivo que reciba un tweet y prediga su emoji asociado?

## Intro
Las herramientas de procesamiento de texto natural han mostrado capacidades muy parecidas a las humanas. Testear su potencial en el contexto de este dataset es interesante puesto a que la variable a predecir es inherentemente subjetiva. En general, se espera que el emoji est√© asociado al car√°cter emocional del tweet en cuesti√≥n, por ende tiene sentido testear modelos que han sido entrenados o ajustados para detectar sentimientos. No obstante, en este desaf√≠o hay emojis que presentan similar valor emocional. Adem√°s puede ser que el emoji corresponda a variables de mayor complejidad, como el sarcasmo del mensaje. Es por esto que el √©xito en la predicci√≥n ser√≠a tarea dif√≠cil incluso para un humano.

Para responder a esta pregunta podemos usar modelos como Na√Øve Bayes, en el cual tomamos en consideraci√≥n la ocurrencia de cada palabra en tweets de cada emoji, informaci√≥n que luego se usa para generar una probabilidad de emoji dado el tweet. Tambi√©n podr√≠a ser interesante usar modelos que tomen en consideraci√≥n la interacci√≥n entre palabras. Un ejemplo de esto son los modelos de lenguaje. Podemos usar modelos de lenguajes pre-entrenados basados en redes neuronales, como es el caso de BERT/BETO, y ajustarlos para la predicci√≥n de emojis.


## Propuesta metodol√≥gica

Para responder a esta pregunta queremos usar distintos m√©todos de clasificaci√≥n. Puede que algunos tengan m√°s √©xito que otros y es de nuestro inter√©s analizar por qu√©, de ser el caso.

Como clasificadores hay muchos, usaremos los los de la lista siguiente:
- Na√Øve Bayes
- Clasificadores basados en Transformers

Antes que preferir una lista extensa de m√©todos, queremos analizar adecuadamente cada uno de ellos. Adem√°s, como este desaf√≠o se enmarc√≥ en la competencia SEMEVAL, contamos con una extensa lista de competidores que incluye sus m√©tricas globales de clasificaci√≥n. Podemos, en la mayor√≠a de los casos, averiguar qu√© m√©todo usaron. De este modo tendremos un an√°lisis global del uso de diferentes m√©todos para clasificaci√≥n multimodal de texto.

**Por qu√© usar Na√Øve Bayes?**

Creemos que este m√©todo, pese a su simpleza, puede dar resultados interesantes en esta tarea. Como ejemplo consideremos el siguiente tweet:

_Nearly halfway to **Christmas** üéÑ 
Let me know, what's your favorite thing about **winter**?
Share this post with someone who celebrates **Christmas** all year round! üéÑ_

Este tweet est√° relacionado con navidad, lo cual es evidente gracias a la presencia de ciertas palabras como: _christmas_ y _winter_. Como consecuencia, est√° muy propenso a que la clase en cuesti√≥n sea aquella del emoji _christmas_tree_, lo cual es efectivmente el caso. Si bien esto es menos claro para otros emoji, podemos generalizar esta idea y asumir que la clase del tweet estar√° dada por las palabras que lo componen. A su vez, cada palabra tendr√° una probabilidad de pertenecer a las clases en cuesti√≥n.

El procedimiento para el clasificador ser√° el siguiente:

``` Dado un par√°metro alfa y un vocabulario, ajustamos un clasificador Na√Øve Bayes en base al conjunto de entrenamiento. Luego testeados la calidad de su evaluaci√≥n con diferentes m√©tricas usando el conjuntos de prueba (test).
```

Una raz√≥n para el uso de este m√©todo es que los resultados de Na√Øve Bayes son altamente interpretables puesto a que a cada palabra se le asigna la probabilidad de pertenecer a las distintas clases. Esto nos da un eje extra de exploraci√≥n que usaremos del siguiente modo, dado un clasificador entrenado : 

```Para cada emoji, seleccionar k palabras con probabilidad m√°s alta de ser catalogadas con el emoji.```

Otra manera de interpretar los resultados del clasificador es el siguiente: para cada palabra poseemos la probabilidad de pertenecer a alguna clase (emoji). Como tenemos 20 emojis (19 respectivamente), entonces esto nos dota de un vector 20-dimensional (resp. 19-d) a valores en [0,1]. Esto nos permite usar alguna t√©cnica de reducci√≥n de dimensionalidad para visualizar el espacio que se genera con tales representaciones. Para esta tarea elegimos umap, pues algunos de los miembros del grupo ya tienen vasta experiencia us√°ndola y afinando sus hiperpar√°metros. En resumen realizamos lo siguiente:

```Para cada palabra del vocabulario, tomar su vector n-dimensional dado por la probabilidad de pertenecer a las n clases. Realizar una reducci√≥n de dimensi√≥n usando UMAP y proyectalos en el plano junto con el color de la clase m√°s probable y con tama√±o del punto dependiendo de cuan fuerte es la probabilidad de pertenecer a su clase m√°s probable. Realizar un an√°lisis cualitativo.```

Para la implementaci√≥n del clasificador usaremos la librer√≠a scikitlearn. Un par√°metro a ajustar es el alpha. Este corresponde a la suavizaci√≥n de la verosimilitud, que est√° dada por la ecuaci√≥n siguiente:

$$ \theta_{y^i} = \frac{N_{y^i}+\alpha}{N_y+\alpha n} $$

Donde $N_{y^i}$ es el n√∫mero de veces que la palabra $i$ aparece en la clase $y$, y $N_y$ es el conteo total de palabras para la clase $y$. El valor $\theta_{y^i}$ corresponde a la probabilidad de que una palabra $i$ aparezca en la clase (emoji) $y$.

Por otro lado, la definici√≥n del vocabulario es importante a la hora de usar NB. Usamos tambi√©n la librer√≠a scikitlearn para esto. Esta posee un par√°metro min_df, que corresponde a la m√≠nima cantidad de ocurrencia que debe tener una palabra para que est√° sea tomada en cuenta en el clasificador. De este modo, un min_df = 1 tomara todas las palabras. Usar un min_df m√°s elevado nos permitir√° analizar solo aquellas palabras que suceden seguido y por ende que portar√°n m√°s informaci√≥n acerca de la pertenencia o no a una cierta clase.

Realizaremos un grid search para ajustar ambos par√°metros en nuestro clasificador. Exploraremos los valores siguientes:
- $\alpha \in \{0.0,0.2,0.4,0.6,0.8,1.0\}$
- $min_df \in \{1,2,3,4,5,6,7,8,9,10\}$
Y escogeremos el ganador en base a la m√©trica macro f1 para ser consistentes con el resultado de la competici√≥n SEMEVAL.

```
Para distintos valores de alpha y min_df, entrenar un clasificador NB y escoger aquel con mayor macro f1
```
