{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "**¿Un Hashtag es más útil a la hora de entrenar un modelo para predecir un emoji?**\n",
    "\n",
    "Para poder responder a la pregunta de si es más efectivo predecir un emoji a partir de hashtags o el contenido del tweet, se debe generar un nuevo data frame, el cual contenga solo los tweets que tienen hashtags, ya que el mantener los tweets sin hashtags no aporta información relevante para esta pregunta. \n",
    "\n",
    "Ahora bien, debido a que los hashtags se escriben sin espacios entre caracteres, no se puede hacer exactamente el mismo pre-procesamiento que se realizó para los caracteres del tweet. Es por esto, que se debe eliminar todo el contenido de cada hashtag que no aporta información sobre el contenido del tweet, en este caso, solo números y puntuación(.,!,#), donde además se debe procurar dejar todo el contenido del hashtag en minúscula.\n",
    "\n",
    "Cabe recalcar, que de ser necesario, se realizará un reajuste en el balance de clases mediante subsampling, puesto que en la base de datos hay una mayor presencia de ciertos emojis, lo que puede generar resultados poco concluyentes.\n",
    "\n",
    "Luego del pre-procesamiento, se deberán crear 2 dataset más, uno que contenga los tweets sin los hashtags y otro con solo los hashtags, ya que con esto podremos aplicar diferentes técnicas de clasificación a cada uno de los 3 data frame y podremos cuantificar la efectividad de los hashtags para predecir un emoji. A partir de esto, se ocupará el método de KNN, puesto que este es usado frecuentemente para búsquedas semánticas (procesamiento de lenguaje natural), asociando k puntos de datos más cercanos del dataset train a el punto de consulta (puede ser con distancia euclidiana), es decir, cuando se entrena el clasificador,  se asociaron k palabras para cada emoji y luego mediremos la distancia de cada palabra del test set con las del train set. \n",
    "\n",
    "Posteriormente, para poder comparar los resultados entre clasificadores y escoger el más óptimo, se ocupará adicionalmente el clasificador que tenga los mejores resultados en la pregunta 1, ya que el procedimiento es análogo en ambas preguntas. \n",
    "\n",
    "En consecuencia, para poder medir la efectividad de cada clasificador y poder hacer una comparación entre ellos, se utilizaran las métricas F1 score y sensibilidad, puesto que existe un desbalance entre clases (cantidad de cada emoji), haciendo que accuracy no sea la mejor métrica en este caso (de igual forma se espera un porcentaje sobre el 70%).\n",
    "\n",
    "Finalmente, se escogieron estos dos clasificadores por sobre el resto, ya que trabajan de una manera más óptima en presencia de multiclases, acertando un mayor número de veces correctamente al emoji correspondiente, lo cual fue previamente observado en el procedimiento para la pregunta 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from string import punctuation\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer # tokenizer especial para tweets\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"df_es_mapping\": \"../../Data/mapping/df_es_mapping.pickle\",\n",
    "    \"df_us_mapping\": \"../../Data/mapping/df_us_mapping.pickle\",\n",
    "    \n",
    "    \"df_es_test\": \"../../Data/test/df_es_test.pickle\",\n",
    "    \"df_us_test\": \"../../Data/test/df_us_test.pickle\",\n",
    "    \n",
    "    \"df_es_train\": \"../../Data/train/df_es_train.pickle\",\n",
    "    \"df_us_train\": \"../../Data/train/df_us_train.pickle\",\n",
    "    \n",
    "    \"df_es_trial\": \"../../Data/trial/df_es_trial.pickle\",\n",
    "    \"df_us_trial\": \"../../Data/trial/df_us_trial.pickle\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_trial = pickle.load(open(file_names[\"df_es_trial\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_trial = pickle.load(open(file_names[\"df_us_trial\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793417168469757952</td>\n",
       "      <td>Es imposible quererte más @ Plaza Del Callao -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718539939063926790</td>\n",
       "      <td>Disfrutando de buena comida con buena compañía...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670562346067193856</td>\n",
       "      <td>Muchísimas Felicidades M!!! Nos vemos pronto! ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>783680728538214400</td>\n",
       "      <td>Y pensar que a esta persona la conozco de hace...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711210617043075073</td>\n",
       "      <td>¡Que buenas son las noches así y que buena com...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text label\n",
       "0  793417168469757952  Es imposible quererte más @ Plaza Del Callao -...     0\n",
       "1  718539939063926790  Disfrutando de buena comida con buena compañía...     4\n",
       "2  670562346067193856  Muchísimas Felicidades M!!! Nos vemos pronto! ...    11\n",
       "3  783680728538214400  Y pensar que a esta persona la conozco de hace...    11\n",
       "4  711210617043075073  ¡Que buenas son las noches así y que buena com...    17"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df_es_train['tokenized_text'] = df_es_train['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "# # df_es_train['tokenized_text'] = df_es_train['text'].str.lower().apply(tt.tokenize) \n",
    "# df_es_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.2 s\n",
      "Wall time: 3.63 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793417168469757952</td>\n",
       "      <td>Es imposible quererte más @ Plaza Del Callao -...</td>\n",
       "      <td>0</td>\n",
       "      <td>[es, imposible, quererte, más, @, plaza, del, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718539939063926790</td>\n",
       "      <td>Disfrutando de buena comida con buena compañía...</td>\n",
       "      <td>4</td>\n",
       "      <td>[disfrutando, de, buena, comida, con, buena, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670562346067193856</td>\n",
       "      <td>Muchísimas Felicidades M!!! Nos vemos pronto! ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[muchísimas, felicidades, m, !, !, !, nos, vem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>783680728538214400</td>\n",
       "      <td>Y pensar que a esta persona la conozco de hace...</td>\n",
       "      <td>11</td>\n",
       "      <td>[y, pensar, que, a, esta, persona, la, conozco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711210617043075073</td>\n",
       "      <td>¡Que buenas son las noches así y que buena com...</td>\n",
       "      <td>17</td>\n",
       "      <td>[¡, que, buenas, son, las, noches, así, y, que...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  793417168469757952  Es imposible quererte más @ Plaza Del Callao -...   \n",
       "1  718539939063926790  Disfrutando de buena comida con buena compañía...   \n",
       "2  670562346067193856  Muchísimas Felicidades M!!! Nos vemos pronto! ...   \n",
       "3  783680728538214400  Y pensar que a esta persona la conozco de hace...   \n",
       "4  711210617043075073  ¡Que buenas son las noches así y que buena com...   \n",
       "\n",
       "  label                                     tokenized_text  \n",
       "0     0  [es, imposible, quererte, más, @, plaza, del, ...  \n",
       "1     4  [disfrutando, de, buena, comida, con, buena, c...  \n",
       "2    11  [muchísimas, felicidades, m, !, !, !, nos, vem...  \n",
       "3    11  [y, pensar, que, a, esta, persona, la, conozco...  \n",
       "4    17  [¡, que, buenas, son, las, noches, así, y, que...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_es_train['tokenized_text'] = df_es_train['text'].str.lower().apply(tt.tokenize) \n",
    "df_es_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Gianluca\n",
      "[nltk_data]     Musso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_es = stopwords.words('spanish')\n",
    "print(stopwords_es[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{', 'se', 'han', 'estábamos', 'fue', 'teniendo', 'sería', 'tenidos', ';', 'esa']\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "stopwords_es_withpunct = set(stopwords_es).union(set(punctuation))\n",
    "print(list(stopwords_es_withpunct)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>length tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793417168469757952</td>\n",
       "      <td>Es imposible quererte más @ Plaza Del Callao -...</td>\n",
       "      <td>0</td>\n",
       "      <td>[imposible, quererte, plaza, callao, madrid]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718539939063926790</td>\n",
       "      <td>Disfrutando de buena comida con buena compañía...</td>\n",
       "      <td>4</td>\n",
       "      <td>[disfrutando, buena, comida, buena, compañía, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670562346067193856</td>\n",
       "      <td>Muchísimas Felicidades M!!! Nos vemos pronto! ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[muchísimas, felicidades, m, vemos, pronto, tk...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>783680728538214400</td>\n",
       "      <td>Y pensar que a esta persona la conozco de hace...</td>\n",
       "      <td>11</td>\n",
       "      <td>[pensar, persona, conozco, hace, quiero, maner...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711210617043075073</td>\n",
       "      <td>¡Que buenas son las noches así y que buena com...</td>\n",
       "      <td>17</td>\n",
       "      <td>[¡, buenas, noches, así, buena, compañía, va, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  793417168469757952  Es imposible quererte más @ Plaza Del Callao -...   \n",
       "1  718539939063926790  Disfrutando de buena comida con buena compañía...   \n",
       "2  670562346067193856  Muchísimas Felicidades M!!! Nos vemos pronto! ...   \n",
       "3  783680728538214400  Y pensar que a esta persona la conozco de hace...   \n",
       "4  711210617043075073  ¡Que buenas son las noches así y que buena com...   \n",
       "\n",
       "  label                                     tokenized_text  length tokenized  \n",
       "0     0       [imposible, quererte, plaza, callao, madrid]                 5  \n",
       "1     4  [disfrutando, buena, comida, buena, compañía, ...                 9  \n",
       "2    11  [muchísimas, felicidades, m, vemos, pronto, tk...                 9  \n",
       "3    11  [pensar, persona, conozco, hace, quiero, maner...                 9  \n",
       "4    17  [¡, buenas, noches, así, buena, compañía, va, ...                 8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_train['tokenized_text'] = df_es_train['tokenized_text'].apply(lambda x: [word for word in x if word not in (stopwords_es_withpunct)])\n",
    "df_es_train[\"length tokenized\"] = df_es_train['tokenized_text'].apply(len)\n",
    "df_es_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# puede ser porter o wnl\n",
    "porter = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.59 s\n",
      "Wall time: 5.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_es_train['StemmedTokenized_text'] = df_es_train['tokenized_text'].apply(lambda x: [porter.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>length tokenized</th>\n",
       "      <th>StemmedTokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793417168469757952</td>\n",
       "      <td>Es imposible quererte más @ Plaza Del Callao -...</td>\n",
       "      <td>0</td>\n",
       "      <td>[imposible, quererte, plaza, callao, madrid]</td>\n",
       "      <td>5</td>\n",
       "      <td>[impos, querert, plaza, callao, madrid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>718539939063926790</td>\n",
       "      <td>Disfrutando de buena comida con buena compañía...</td>\n",
       "      <td>4</td>\n",
       "      <td>[disfrutando, buena, comida, buena, compañía, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[disfrutando, buena, comida, buena, compañía, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>670562346067193856</td>\n",
       "      <td>Muchísimas Felicidades M!!! Nos vemos pronto! ...</td>\n",
       "      <td>11</td>\n",
       "      <td>[muchísimas, felicidades, m, vemos, pronto, tk...</td>\n",
       "      <td>9</td>\n",
       "      <td>[muchísima, felicidad, m, vemo, pronto, tkkkkk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>783680728538214400</td>\n",
       "      <td>Y pensar que a esta persona la conozco de hace...</td>\n",
       "      <td>11</td>\n",
       "      <td>[pensar, persona, conozco, hace, quiero, maner...</td>\n",
       "      <td>9</td>\n",
       "      <td>[pensar, persona, conozco, hace, quiero, maner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>711210617043075073</td>\n",
       "      <td>¡Que buenas son las noches así y que buena com...</td>\n",
       "      <td>17</td>\n",
       "      <td>[¡, buenas, noches, así, buena, compañía, va, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>[¡, buena, noch, así, buena, compañía, va, @user]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  793417168469757952  Es imposible quererte más @ Plaza Del Callao -...   \n",
       "1  718539939063926790  Disfrutando de buena comida con buena compañía...   \n",
       "2  670562346067193856  Muchísimas Felicidades M!!! Nos vemos pronto! ...   \n",
       "3  783680728538214400  Y pensar que a esta persona la conozco de hace...   \n",
       "4  711210617043075073  ¡Que buenas son las noches así y que buena com...   \n",
       "\n",
       "  label                                     tokenized_text  length tokenized  \\\n",
       "0     0       [imposible, quererte, plaza, callao, madrid]                 5   \n",
       "1     4  [disfrutando, buena, comida, buena, compañía, ...                 9   \n",
       "2    11  [muchísimas, felicidades, m, vemos, pronto, tk...                 9   \n",
       "3    11  [pensar, persona, conozco, hace, quiero, maner...                 9   \n",
       "4    17  [¡, buenas, noches, así, buena, compañía, va, ...                 8   \n",
       "\n",
       "                               StemmedTokenized_text  \n",
       "0            [impos, querert, plaza, callao, madrid]  \n",
       "1  [disfrutando, buena, comida, buena, compañía, ...  \n",
       "2  [muchísima, felicidad, m, vemo, pronto, tkkkkk...  \n",
       "3  [pensar, persona, conozco, hace, quiero, maner...  \n",
       "4  [¡, buena, noch, así, buena, compañía, va, @user]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar df de tweets que solo tengan hastags\n",
    "\n",
    "Sacar puntuación y números de cada hashtag, además de dejar en minúscula.\n",
    "\n",
    "Hacer df sin hastags\n",
    "\n",
    "hacer df solo con los hastags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[mama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[boy, girls, friends, day, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[twinseurs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[sananton2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[Mallorca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81300</th>\n",
       "      <td>[aprovechandoelverano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81307</th>\n",
       "      <td>[family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81308</th>\n",
       "      <td>[codigodescuento, SUITATP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81316</th>\n",
       "      <td>[Baco, madrid2016]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81321</th>\n",
       "      <td>[friends, Madrid, Spain, cena]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24025 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text\n",
       "11                               [mama]\n",
       "14     [boy, girls, friends, day, work]\n",
       "27                          [twinseurs]\n",
       "31                       [sananton2016]\n",
       "32                           [Mallorca]\n",
       "...                                 ...\n",
       "81300            [aprovechandoelverano]\n",
       "81307                          [family]\n",
       "81308        [codigodescuento, SUITATP]\n",
       "81316                [Baco, madrid2016]\n",
       "81321    [friends, Madrid, Spain, cena]\n",
       "\n",
       "[24025 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "df_es_only_hashtags = pd.DataFrame()\n",
    "df_es_only_hashtags['text']=df_es_train['text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))\n",
    "df_es_only_hashtags[df_es_only_hashtags['text'].apply(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>length tokenized</th>\n",
       "      <th>StemmedTokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>732910832930062336</td>\n",
       "      <td>Como me gusta reunirme con mi madre aun que si...</td>\n",
       "      <td>5</td>\n",
       "      <td>[gusta, reunirme, madre, aun, siempre, caen, b...</td>\n",
       "      <td>9</td>\n",
       "      <td>[gusta, reunirm, madr, aun, siempr, caen, bron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>795284818866995200</td>\n",
       "      <td>Descansando un poco en el trabajo #boy #girls ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[descansando, trabajo, #boy, #girls, #friends,...</td>\n",
       "      <td>9</td>\n",
       "      <td>[descansando, trabajo, #boy, #girl, #friend, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>694634313728532480</td>\n",
       "      <td>@user ya tenemos nuestro medidor de altura par...</td>\n",
       "      <td>1</td>\n",
       "      <td>[@user, medidor, altura, #twinseurs, algemesí]</td>\n",
       "      <td>5</td>\n",
       "      <td>[@user, medidor, altura, #twinseur, algemesí]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>689892121680056321</td>\n",
       "      <td>Los 4 fantásticamente quemados #sananton2016 @...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, fantásticamente, quemados, #sananton2016, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[4, fantásticament, quemado, #sananton2016, pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>795575808647696385</td>\n",
       "      <td>Sweet home! #Mallorca (@ Aeropuerto de Palma d...</td>\n",
       "      <td>4</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81300</th>\n",
       "      <td>761357182101254144</td>\n",
       "      <td>Las tardes son de Aloha #aprovechandoelverano ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[tardes, aloha, #aprovechandoelverano, aloha, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[tard, aloha, #aprovechandoelverano, aloha, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81307</th>\n",
       "      <td>748128577313464321</td>\n",
       "      <td>Simplemente, gracias . #family @ Barrio Llored...</td>\n",
       "      <td>0</td>\n",
       "      <td>[simplemente, gracias, #family, barrio, llored...</td>\n",
       "      <td>6</td>\n",
       "      <td>[simplement, gracia, #famili, barrio, lloreda,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81308</th>\n",
       "      <td>664469119396368384</td>\n",
       "      <td>Cuantos conocéis así?? Jaja pontemasfuerte #co...</td>\n",
       "      <td>2</td>\n",
       "      <td>[cuantos, conocéis, así, jaja, pontemasfuerte,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[cuanto, conocéi, así, jaja, pontemasfuert, #c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81316</th>\n",
       "      <td>705906790777688064</td>\n",
       "      <td>Templo de #Baco. Parque El Capricho. #madrid20...</td>\n",
       "      <td>9</td>\n",
       "      <td>[templo, #baco, parque, capricho, #madrid2016,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[templo, #baco, parqu, capricho, #madrid2016, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81321</th>\n",
       "      <td>693547861850656768</td>\n",
       "      <td>Cena en Madrid. Plan perfecto para descansar d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>11</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24025 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "11     732910832930062336  Como me gusta reunirme con mi madre aun que si...   \n",
       "14     795284818866995200  Descansando un poco en el trabajo #boy #girls ...   \n",
       "27     694634313728532480  @user ya tenemos nuestro medidor de altura par...   \n",
       "31     689892121680056321  Los 4 fantásticamente quemados #sananton2016 @...   \n",
       "32     795575808647696385  Sweet home! #Mallorca (@ Aeropuerto de Palma d...   \n",
       "...                   ...                                                ...   \n",
       "81300  761357182101254144  Las tardes son de Aloha #aprovechandoelverano ...   \n",
       "81307  748128577313464321  Simplemente, gracias . #family @ Barrio Llored...   \n",
       "81308  664469119396368384  Cuantos conocéis así?? Jaja pontemasfuerte #co...   \n",
       "81316  705906790777688064  Templo de #Baco. Parque El Capricho. #madrid20...   \n",
       "81321  693547861850656768  Cena en Madrid. Plan perfecto para descansar d...   \n",
       "\n",
       "      label                                     tokenized_text  \\\n",
       "11        5  [gusta, reunirme, madre, aun, siempre, caen, b...   \n",
       "14       13  [descansando, trabajo, #boy, #girls, #friends,...   \n",
       "27        1     [@user, medidor, altura, #twinseurs, algemesí]   \n",
       "31        2  [4, fantásticamente, quemados, #sananton2016, ...   \n",
       "32        4  [sweet, home, #mallorca, aeropuerto, palma, ma...   \n",
       "...     ...                                                ...   \n",
       "81300    13  [tardes, aloha, #aprovechandoelverano, aloha, ...   \n",
       "81307     0  [simplemente, gracias, #family, barrio, llored...   \n",
       "81308     2  [cuantos, conocéis, así, jaja, pontemasfuerte,...   \n",
       "81316     9  [templo, #baco, parque, capricho, #madrid2016,...   \n",
       "81321     1  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "       length tokenized                              StemmedTokenized_text  \n",
       "11                    9  [gusta, reunirm, madr, aun, siempr, caen, bron...  \n",
       "14                    9  [descansando, trabajo, #boy, #girl, #friend, #...  \n",
       "27                    5      [@user, medidor, altura, #twinseur, algemesí]  \n",
       "31                    9  [4, fantásticament, quemado, #sananton2016, pu...  \n",
       "32                    7  [sweet, home, #mallorca, aeropuerto, palma, ma...  \n",
       "...                 ...                                                ...  \n",
       "81300                 5  [tard, aloha, #aprovechandoelverano, aloha, es...  \n",
       "81307                 6  [simplement, gracia, #famili, barrio, lloreda,...  \n",
       "81308                 8  [cuanto, conocéi, así, jaja, pontemasfuert, #c...  \n",
       "81316                 8  [templo, #baco, parqu, capricho, #madrid2016, ...  \n",
       "81321                11  [cena, madrid, plan, perfecto, descansar, estu...  \n",
       "\n",
       "[24025 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este es el dataset de train completo filtrado con solo los tweets que tienen hashtag\n",
    "df_es_train_filtered = df_es_train[df_es_only_hashtags['text'].apply(lambda d: len(d)) > 0]\n",
    "df_es_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianluca Musso\\AppData\\Local\\Temp\\ipykernel_5148\\1235189460.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_es_train_filtered['StemmedTokenized_text_wo_hashtag'] = df_es_train_filtered['StemmedTokenized_text'].apply(lambda li: [word for word in li if not word.startswith('#')])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>length tokenized</th>\n",
       "      <th>StemmedTokenized_text</th>\n",
       "      <th>StemmedTokenized_text_wo_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>732910832930062336</td>\n",
       "      <td>Como me gusta reunirme con mi madre aun que si...</td>\n",
       "      <td>5</td>\n",
       "      <td>[gusta, reunirme, madre, aun, siempre, caen, b...</td>\n",
       "      <td>9</td>\n",
       "      <td>[gusta, reunirm, madr, aun, siempr, caen, bron...</td>\n",
       "      <td>[gusta, reunirm, madr, aun, siempr, caen, bron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>795284818866995200</td>\n",
       "      <td>Descansando un poco en el trabajo #boy #girls ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[descansando, trabajo, #boy, #girls, #friends,...</td>\n",
       "      <td>9</td>\n",
       "      <td>[descansando, trabajo, #boy, #girl, #friend, #...</td>\n",
       "      <td>[descansando, trabajo, madrid, spain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>694634313728532480</td>\n",
       "      <td>@user ya tenemos nuestro medidor de altura par...</td>\n",
       "      <td>1</td>\n",
       "      <td>[@user, medidor, altura, #twinseurs, algemesí]</td>\n",
       "      <td>5</td>\n",
       "      <td>[@user, medidor, altura, #twinseur, algemesí]</td>\n",
       "      <td>[@user, medidor, altura, algemesí]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>689892121680056321</td>\n",
       "      <td>Los 4 fantásticamente quemados #sananton2016 @...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, fantásticamente, quemados, #sananton2016, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[4, fantásticament, quemado, #sananton2016, pu...</td>\n",
       "      <td>[4, fantásticament, quemado, puerto, lápice, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>795575808647696385</td>\n",
       "      <td>Sweet home! #Mallorca (@ Aeropuerto de Palma d...</td>\n",
       "      <td>4</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "      <td>[sweet, home, aeropuerto, palma, mallorca, @user]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81300</th>\n",
       "      <td>761357182101254144</td>\n",
       "      <td>Las tardes son de Aloha #aprovechandoelverano ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[tardes, aloha, #aprovechandoelverano, aloha, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[tard, aloha, #aprovechandoelverano, aloha, es...</td>\n",
       "      <td>[tard, aloha, aloha, escollera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81307</th>\n",
       "      <td>748128577313464321</td>\n",
       "      <td>Simplemente, gracias . #family @ Barrio Llored...</td>\n",
       "      <td>0</td>\n",
       "      <td>[simplemente, gracias, #family, barrio, llored...</td>\n",
       "      <td>6</td>\n",
       "      <td>[simplement, gracia, #famili, barrio, lloreda,...</td>\n",
       "      <td>[simplement, gracia, barrio, lloreda, badalona]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81308</th>\n",
       "      <td>664469119396368384</td>\n",
       "      <td>Cuantos conocéis así?? Jaja pontemasfuerte #co...</td>\n",
       "      <td>2</td>\n",
       "      <td>[cuantos, conocéis, así, jaja, pontemasfuerte,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[cuanto, conocéi, así, jaja, pontemasfuert, #c...</td>\n",
       "      <td>[cuanto, conocéi, así, jaja, pontemasfuert, s2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81316</th>\n",
       "      <td>705906790777688064</td>\n",
       "      <td>Templo de #Baco. Parque El Capricho. #madrid20...</td>\n",
       "      <td>9</td>\n",
       "      <td>[templo, #baco, parque, capricho, #madrid2016,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[templo, #baco, parqu, capricho, #madrid2016, ...</td>\n",
       "      <td>[templo, parqu, capricho, parqu, capricho, mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81321</th>\n",
       "      <td>693547861850656768</td>\n",
       "      <td>Cena en Madrid. Plan perfecto para descansar d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>11</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24025 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "11     732910832930062336  Como me gusta reunirme con mi madre aun que si...   \n",
       "14     795284818866995200  Descansando un poco en el trabajo #boy #girls ...   \n",
       "27     694634313728532480  @user ya tenemos nuestro medidor de altura par...   \n",
       "31     689892121680056321  Los 4 fantásticamente quemados #sananton2016 @...   \n",
       "32     795575808647696385  Sweet home! #Mallorca (@ Aeropuerto de Palma d...   \n",
       "...                   ...                                                ...   \n",
       "81300  761357182101254144  Las tardes son de Aloha #aprovechandoelverano ...   \n",
       "81307  748128577313464321  Simplemente, gracias . #family @ Barrio Llored...   \n",
       "81308  664469119396368384  Cuantos conocéis así?? Jaja pontemasfuerte #co...   \n",
       "81316  705906790777688064  Templo de #Baco. Parque El Capricho. #madrid20...   \n",
       "81321  693547861850656768  Cena en Madrid. Plan perfecto para descansar d...   \n",
       "\n",
       "      label                                     tokenized_text  \\\n",
       "11        5  [gusta, reunirme, madre, aun, siempre, caen, b...   \n",
       "14       13  [descansando, trabajo, #boy, #girls, #friends,...   \n",
       "27        1     [@user, medidor, altura, #twinseurs, algemesí]   \n",
       "31        2  [4, fantásticamente, quemados, #sananton2016, ...   \n",
       "32        4  [sweet, home, #mallorca, aeropuerto, palma, ma...   \n",
       "...     ...                                                ...   \n",
       "81300    13  [tardes, aloha, #aprovechandoelverano, aloha, ...   \n",
       "81307     0  [simplemente, gracias, #family, barrio, llored...   \n",
       "81308     2  [cuantos, conocéis, así, jaja, pontemasfuerte,...   \n",
       "81316     9  [templo, #baco, parque, capricho, #madrid2016,...   \n",
       "81321     1  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "       length tokenized                              StemmedTokenized_text  \\\n",
       "11                    9  [gusta, reunirm, madr, aun, siempr, caen, bron...   \n",
       "14                    9  [descansando, trabajo, #boy, #girl, #friend, #...   \n",
       "27                    5      [@user, medidor, altura, #twinseur, algemesí]   \n",
       "31                    9  [4, fantásticament, quemado, #sananton2016, pu...   \n",
       "32                    7  [sweet, home, #mallorca, aeropuerto, palma, ma...   \n",
       "...                 ...                                                ...   \n",
       "81300                 5  [tard, aloha, #aprovechandoelverano, aloha, es...   \n",
       "81307                 6  [simplement, gracia, #famili, barrio, lloreda,...   \n",
       "81308                 8  [cuanto, conocéi, así, jaja, pontemasfuert, #c...   \n",
       "81316                 8  [templo, #baco, parqu, capricho, #madrid2016, ...   \n",
       "81321                11  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "                        StemmedTokenized_text_wo_hashtag  \n",
       "11     [gusta, reunirm, madr, aun, siempr, caen, bron...  \n",
       "14                 [descansando, trabajo, madrid, spain]  \n",
       "27                    [@user, medidor, altura, algemesí]  \n",
       "31     [4, fantásticament, quemado, puerto, lápice, c...  \n",
       "32     [sweet, home, aeropuerto, palma, mallorca, @user]  \n",
       "...                                                  ...  \n",
       "81300                    [tard, aloha, aloha, escollera]  \n",
       "81307    [simplement, gracia, barrio, lloreda, badalona]  \n",
       "81308  [cuanto, conocéi, así, jaja, pontemasfuert, s2...  \n",
       "81316  [templo, parqu, capricho, parqu, capricho, mad...  \n",
       "81321  [cena, madrid, plan, perfecto, descansar, estu...  \n",
       "\n",
       "[24025 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se agrega al train las columnas tokenizadas con y sin hashtags\n",
    "df_es_train_filtered['StemmedTokenized_text_wo_hashtag'] = df_es_train_filtered['StemmedTokenized_text'].apply(lambda li: [word for word in li if not word.startswith('#')])\n",
    "df_es_train_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gianluca Musso\\AppData\\Local\\Temp\\ipykernel_5148\\1891238454.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_es_train_filtered['StemmedTokenized_text_as_str'] = df_es_train_filtered['StemmedTokenized_text'].astype(object).apply(lambda x: ' '.join([str(i) for i in x]))\n",
      "C:\\Users\\Gianluca Musso\\AppData\\Local\\Temp\\ipykernel_5148\\1891238454.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_es_train_filtered['StemmedTokenized_text_wo_hashtag_as_str'] = df_es_train_filtered['StemmedTokenized_text_wo_hashtag'].astype(object).apply(lambda x: ' '.join([str(i) for i in x]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>length tokenized</th>\n",
       "      <th>StemmedTokenized_text</th>\n",
       "      <th>StemmedTokenized_text_wo_hashtag</th>\n",
       "      <th>StemmedTokenized_text_as_str</th>\n",
       "      <th>StemmedTokenized_text_wo_hashtag_as_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>732910832930062336</td>\n",
       "      <td>Como me gusta reunirme con mi madre aun que si...</td>\n",
       "      <td>5</td>\n",
       "      <td>[gusta, reunirme, madre, aun, siempre, caen, b...</td>\n",
       "      <td>9</td>\n",
       "      <td>[gusta, reunirm, madr, aun, siempr, caen, bron...</td>\n",
       "      <td>[gusta, reunirm, madr, aun, siempr, caen, bron...</td>\n",
       "      <td>gusta reunirm madr aun siempr caen bronca #mama …</td>\n",
       "      <td>gusta reunirm madr aun siempr caen bronca …</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>795284818866995200</td>\n",
       "      <td>Descansando un poco en el trabajo #boy #girls ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[descansando, trabajo, #boy, #girls, #friends,...</td>\n",
       "      <td>9</td>\n",
       "      <td>[descansando, trabajo, #boy, #girl, #friend, #...</td>\n",
       "      <td>[descansando, trabajo, madrid, spain]</td>\n",
       "      <td>descansando trabajo #boy #girl #friend #day #w...</td>\n",
       "      <td>descansando trabajo madrid spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>694634313728532480</td>\n",
       "      <td>@user ya tenemos nuestro medidor de altura par...</td>\n",
       "      <td>1</td>\n",
       "      <td>[@user, medidor, altura, #twinseurs, algemesí]</td>\n",
       "      <td>5</td>\n",
       "      <td>[@user, medidor, altura, #twinseur, algemesí]</td>\n",
       "      <td>[@user, medidor, altura, algemesí]</td>\n",
       "      <td>@user medidor altura #twinseur algemesí</td>\n",
       "      <td>@user medidor altura algemesí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>689892121680056321</td>\n",
       "      <td>Los 4 fantásticamente quemados #sananton2016 @...</td>\n",
       "      <td>2</td>\n",
       "      <td>[4, fantásticamente, quemados, #sananton2016, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[4, fantásticament, quemado, #sananton2016, pu...</td>\n",
       "      <td>[4, fantásticament, quemado, puerto, lápice, c...</td>\n",
       "      <td>4 fantásticament quemado #sananton2016 puerto ...</td>\n",
       "      <td>4 fantásticament quemado puerto lápice castill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>795575808647696385</td>\n",
       "      <td>Sweet home! #Mallorca (@ Aeropuerto de Palma d...</td>\n",
       "      <td>4</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "      <td>7</td>\n",
       "      <td>[sweet, home, #mallorca, aeropuerto, palma, ma...</td>\n",
       "      <td>[sweet, home, aeropuerto, palma, mallorca, @user]</td>\n",
       "      <td>sweet home #mallorca aeropuerto palma mallorca...</td>\n",
       "      <td>sweet home aeropuerto palma mallorca @user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81300</th>\n",
       "      <td>761357182101254144</td>\n",
       "      <td>Las tardes son de Aloha #aprovechandoelverano ...</td>\n",
       "      <td>13</td>\n",
       "      <td>[tardes, aloha, #aprovechandoelverano, aloha, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[tard, aloha, #aprovechandoelverano, aloha, es...</td>\n",
       "      <td>[tard, aloha, aloha, escollera]</td>\n",
       "      <td>tard aloha #aprovechandoelverano aloha escollera</td>\n",
       "      <td>tard aloha aloha escollera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81307</th>\n",
       "      <td>748128577313464321</td>\n",
       "      <td>Simplemente, gracias . #family @ Barrio Llored...</td>\n",
       "      <td>0</td>\n",
       "      <td>[simplemente, gracias, #family, barrio, llored...</td>\n",
       "      <td>6</td>\n",
       "      <td>[simplement, gracia, #famili, barrio, lloreda,...</td>\n",
       "      <td>[simplement, gracia, barrio, lloreda, badalona]</td>\n",
       "      <td>simplement gracia #famili barrio lloreda badalona</td>\n",
       "      <td>simplement gracia barrio lloreda badalona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81308</th>\n",
       "      <td>664469119396368384</td>\n",
       "      <td>Cuantos conocéis así?? Jaja pontemasfuerte #co...</td>\n",
       "      <td>2</td>\n",
       "      <td>[cuantos, conocéis, así, jaja, pontemasfuerte,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[cuanto, conocéi, así, jaja, pontemasfuert, #c...</td>\n",
       "      <td>[cuanto, conocéi, así, jaja, pontemasfuert, s2...</td>\n",
       "      <td>cuanto conocéi así jaja pontemasfuert #codigod...</td>\n",
       "      <td>cuanto conocéi así jaja pontemasfuert s2fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81316</th>\n",
       "      <td>705906790777688064</td>\n",
       "      <td>Templo de #Baco. Parque El Capricho. #madrid20...</td>\n",
       "      <td>9</td>\n",
       "      <td>[templo, #baco, parque, capricho, #madrid2016,...</td>\n",
       "      <td>8</td>\n",
       "      <td>[templo, #baco, parqu, capricho, #madrid2016, ...</td>\n",
       "      <td>[templo, parqu, capricho, parqu, capricho, mad...</td>\n",
       "      <td>templo #baco parqu capricho #madrid2016 parqu ...</td>\n",
       "      <td>templo parqu capricho parqu capricho madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81321</th>\n",
       "      <td>693547861850656768</td>\n",
       "      <td>Cena en Madrid. Plan perfecto para descansar d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>11</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>[cena, madrid, plan, perfecto, descansar, estu...</td>\n",
       "      <td>cena madrid plan perfecto descansar estudio #f...</td>\n",
       "      <td>cena madrid plan perfecto descansar estudio …</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24025 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "11     732910832930062336  Como me gusta reunirme con mi madre aun que si...   \n",
       "14     795284818866995200  Descansando un poco en el trabajo #boy #girls ...   \n",
       "27     694634313728532480  @user ya tenemos nuestro medidor de altura par...   \n",
       "31     689892121680056321  Los 4 fantásticamente quemados #sananton2016 @...   \n",
       "32     795575808647696385  Sweet home! #Mallorca (@ Aeropuerto de Palma d...   \n",
       "...                   ...                                                ...   \n",
       "81300  761357182101254144  Las tardes son de Aloha #aprovechandoelverano ...   \n",
       "81307  748128577313464321  Simplemente, gracias . #family @ Barrio Llored...   \n",
       "81308  664469119396368384  Cuantos conocéis así?? Jaja pontemasfuerte #co...   \n",
       "81316  705906790777688064  Templo de #Baco. Parque El Capricho. #madrid20...   \n",
       "81321  693547861850656768  Cena en Madrid. Plan perfecto para descansar d...   \n",
       "\n",
       "      label                                     tokenized_text  \\\n",
       "11        5  [gusta, reunirme, madre, aun, siempre, caen, b...   \n",
       "14       13  [descansando, trabajo, #boy, #girls, #friends,...   \n",
       "27        1     [@user, medidor, altura, #twinseurs, algemesí]   \n",
       "31        2  [4, fantásticamente, quemados, #sananton2016, ...   \n",
       "32        4  [sweet, home, #mallorca, aeropuerto, palma, ma...   \n",
       "...     ...                                                ...   \n",
       "81300    13  [tardes, aloha, #aprovechandoelverano, aloha, ...   \n",
       "81307     0  [simplemente, gracias, #family, barrio, llored...   \n",
       "81308     2  [cuantos, conocéis, así, jaja, pontemasfuerte,...   \n",
       "81316     9  [templo, #baco, parque, capricho, #madrid2016,...   \n",
       "81321     1  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "       length tokenized                              StemmedTokenized_text  \\\n",
       "11                    9  [gusta, reunirm, madr, aun, siempr, caen, bron...   \n",
       "14                    9  [descansando, trabajo, #boy, #girl, #friend, #...   \n",
       "27                    5      [@user, medidor, altura, #twinseur, algemesí]   \n",
       "31                    9  [4, fantásticament, quemado, #sananton2016, pu...   \n",
       "32                    7  [sweet, home, #mallorca, aeropuerto, palma, ma...   \n",
       "...                 ...                                                ...   \n",
       "81300                 5  [tard, aloha, #aprovechandoelverano, aloha, es...   \n",
       "81307                 6  [simplement, gracia, #famili, barrio, lloreda,...   \n",
       "81308                 8  [cuanto, conocéi, así, jaja, pontemasfuert, #c...   \n",
       "81316                 8  [templo, #baco, parqu, capricho, #madrid2016, ...   \n",
       "81321                11  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "                        StemmedTokenized_text_wo_hashtag  \\\n",
       "11     [gusta, reunirm, madr, aun, siempr, caen, bron...   \n",
       "14                 [descansando, trabajo, madrid, spain]   \n",
       "27                    [@user, medidor, altura, algemesí]   \n",
       "31     [4, fantásticament, quemado, puerto, lápice, c...   \n",
       "32     [sweet, home, aeropuerto, palma, mallorca, @user]   \n",
       "...                                                  ...   \n",
       "81300                    [tard, aloha, aloha, escollera]   \n",
       "81307    [simplement, gracia, barrio, lloreda, badalona]   \n",
       "81308  [cuanto, conocéi, así, jaja, pontemasfuert, s2...   \n",
       "81316  [templo, parqu, capricho, parqu, capricho, mad...   \n",
       "81321  [cena, madrid, plan, perfecto, descansar, estu...   \n",
       "\n",
       "                            StemmedTokenized_text_as_str  \\\n",
       "11     gusta reunirm madr aun siempr caen bronca #mama …   \n",
       "14     descansando trabajo #boy #girl #friend #day #w...   \n",
       "27               @user medidor altura #twinseur algemesí   \n",
       "31     4 fantásticament quemado #sananton2016 puerto ...   \n",
       "32     sweet home #mallorca aeropuerto palma mallorca...   \n",
       "...                                                  ...   \n",
       "81300   tard aloha #aprovechandoelverano aloha escollera   \n",
       "81307  simplement gracia #famili barrio lloreda badalona   \n",
       "81308  cuanto conocéi así jaja pontemasfuert #codigod...   \n",
       "81316  templo #baco parqu capricho #madrid2016 parqu ...   \n",
       "81321  cena madrid plan perfecto descansar estudio #f...   \n",
       "\n",
       "                 StemmedTokenized_text_wo_hashtag_as_str  \n",
       "11           gusta reunirm madr aun siempr caen bronca …  \n",
       "14                      descansando trabajo madrid spain  \n",
       "27                         @user medidor altura algemesí  \n",
       "31     4 fantásticament quemado puerto lápice castill...  \n",
       "32            sweet home aeropuerto palma mallorca @user  \n",
       "...                                                  ...  \n",
       "81300                         tard aloha aloha escollera  \n",
       "81307          simplement gracia barrio lloreda badalona  \n",
       "81308        cuanto conocéi así jaja pontemasfuert s2fit  \n",
       "81316        templo parqu capricho parqu capricho madrid  \n",
       "81321      cena madrid plan perfecto descansar estudio …  \n",
       "\n",
       "[24025 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_train_filtered['StemmedTokenized_text_as_str'] = df_es_train_filtered['StemmedTokenized_text'].astype(object).apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "df_es_train_filtered['StemmedTokenized_text_wo_hashtag_as_str'] = df_es_train_filtered['StemmedTokenized_text_wo_hashtag'].astype(object).apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "df_es_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics without Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24025x20323 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 110853 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_es_train_filtered['StemmedTokenized_text_wo_hashtag_as_str'])\n",
    "y = df_es_train_filtered['label']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenar knn con hashtags\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# comparar metricas como recall precision accuracy f1\n",
    "\n",
    "#split dataset into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.43      0.27      1315\n",
      "           1       0.18      0.39      0.25      1232\n",
      "          10       0.05      0.03      0.04       270\n",
      "          11       0.03      0.01      0.02       167\n",
      "          12       0.00      0.00      0.00       137\n",
      "          13       0.04      0.05      0.05       249\n",
      "          14       0.00      0.00      0.00        81\n",
      "          15       0.03      0.02      0.02       109\n",
      "          16       0.11      0.05      0.07       131\n",
      "          17       0.25      0.03      0.05        70\n",
      "          18       0.10      0.05      0.07       239\n",
      "           2       0.15      0.02      0.04       745\n",
      "           3       0.10      0.01      0.02       226\n",
      "           4       0.14      0.04      0.06       551\n",
      "           5       0.04      0.01      0.02       284\n",
      "           6       0.26      0.04      0.07       332\n",
      "           7       0.12      0.01      0.02       316\n",
      "           8       0.19      0.01      0.02       240\n",
      "           9       0.29      0.28      0.28       514\n",
      "\n",
      "    accuracy                           0.18      7208\n",
      "   macro avg       0.12      0.08      0.07      7208\n",
      "weighted avg       0.15      0.18      0.14      7208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.42\n",
      "Accuracy of K-NN classifier on test set: 0.18\n"
     ]
    }
   ],
   "source": [
    "#Checking performance on the training set\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "#Checking performance on the test set\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics with Hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24025x44091 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 172380 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df_es_train_filtered['StemmedTokenized_text_as_str'])\n",
    "y = df_es_train_filtered['label']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entrenar knn con hashtags\n",
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# comparar metricas como recall precision accuracy f1\n",
    "\n",
    "#split dataset into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.37      0.28      1315\n",
      "           1       0.18      0.57      0.27      1232\n",
      "          10       0.11      0.04      0.06       270\n",
      "          11       0.05      0.02      0.03       167\n",
      "          12       0.00      0.00      0.00       137\n",
      "          13       0.22      0.02      0.03       249\n",
      "          14       0.00      0.00      0.00        81\n",
      "          15       0.25      0.03      0.05       109\n",
      "          16       0.38      0.02      0.04       131\n",
      "          17       0.12      0.03      0.05        70\n",
      "          18       0.03      0.02      0.02       239\n",
      "           2       0.17      0.03      0.04       745\n",
      "           3       0.08      0.01      0.02       226\n",
      "           4       0.30      0.03      0.06       551\n",
      "           5       0.09      0.01      0.02       284\n",
      "           6       0.44      0.02      0.05       332\n",
      "           7       0.58      0.02      0.04       316\n",
      "           8       0.40      0.01      0.02       240\n",
      "           9       0.50      0.30      0.37       514\n",
      "\n",
      "    accuracy                           0.20      7208\n",
      "   macro avg       0.22      0.08      0.08      7208\n",
      "weighted avg       0.24      0.20      0.14      7208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.44\n",
      "Accuracy of K-NN classifier on test set: 0.20\n"
     ]
    }
   ],
   "source": [
    "#Checking performance on the training set\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "#Checking performance on the test set\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Atribute</th>\n",
       "      <th>clasifier_w_hashtags</th>\n",
       "      <th>clasifier_wo_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy train_set</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accuracy test_set</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Atribute  clasifier_w_hashtags  clasifier_wo_hashtags\n",
       "0           precision                  0.22                   0.12\n",
       "1              recall                  0.08                   0.08\n",
       "2            f1-score                  0.08                   0.07\n",
       "3  accuracy train_set                  0.44                   0.42\n",
       "4   accuracy test_set                  0.20                   0.18"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "#import seaborn\n",
    "#seaborn.set(style='ticks')\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Atribute'] = ['precision', 'recall', 'f1-score', 'accuracy train_set', 'accuracy test_set']\n",
    "df['clasifier_w_hashtags'] = [0.22, 0.08, 0.08, 0.44, 0.20]\n",
    "df['clasifier_wo_hashtags'] = [0.12, 0.08, 0.07, 0.42, 0.18] \n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Atribute'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.bar(x='Atribute')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ed512e59b1857458359635d47e777e7171a2fdd13f9ca7ea3b3764edb350a14"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
