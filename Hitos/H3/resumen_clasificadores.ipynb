{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hito 3 - Clasificadores\n",
    "## Para cada idioma, ¬øsomos capaces de ajustar un modelo predictivo que reciba un tweet y prediga su emoji asociado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las herramientas de procesamiento de texto natural han mostrado capacidades muy parecidas a las humanas. Testear su potencial en el contexto de este dataset es interesante puesto a que la variable a predecir es inherentemente subjetiva. En general, se espera que el emoji est√© asociado al car√°cter emocional del tweet en cuesti√≥n, por ende tiene sentido testear modelos que han sido entrenados o ajustados para detectar sentimientos. No obstante, en este desaf√≠o hay emojis que presentan similar valor emocional. Adem√°s puede ser que el emoji corresponda a variables de mayor complejidad, como el sarcasmo del mensaje. Es por esto que el √©xito en la predicci√≥n ser√≠a tarea dif√≠cil incluso para un humano.\n",
    "\n",
    "Para responder a esta pregunta podemos usar modelos como Na√Øve Bayes, en el cual tomamos en consideraci√≥n la ocurrencia de cada palabra en tweets de cada emoji, informaci√≥n que luego se usa para generar una probabilidad de emoji dado el tweet. Tambi√©n podr√≠a ser interesante usar modelos que tomen en consideraci√≥n la interacci√≥n entre palabras. Un ejemplo de esto son los modelos de lenguaje. Podemos usar modelos de lenguajes pre-entrenados basados en redes neuronales, como es el caso de BERT/BETO, y ajustarlos para la predicci√≥n de emojis.\n",
    "\n",
    "\n",
    "## Propuesta metodol√≥gica\n",
    "\n",
    "Para responder a esta pregunta queremos usar distintos m√©todos de clasificaci√≥n. Puede que algunos tengan m√°s √©xito que otros y es de nuestro inter√©s analizar por qu√©, de ser el caso.\n",
    "\n",
    "Como clasificadores hay muchos, usaremos los los de la lista siguiente:\n",
    "- Na√Øve Bayes [(1)](#ref1)\n",
    "- Clasificadores basados en Transformers\n",
    "\n",
    "Antes que preferir una lista extensa de m√©todos, queremos analizar adecuadamente cada uno de ellos. Adem√°s, como este desaf√≠o se enmarc√≥ en la competencia SEMEVAL, contamos con una extensa lista de competidores que incluye sus m√©tricas globales de clasificaci√≥n. Podemos, en la mayor√≠a de los casos, averiguar qu√© m√©todo usaron. De este modo tendremos un an√°lisis global del uso de diferentes m√©todos para clasificaci√≥n multimodal de texto.\n",
    "\n",
    "**Por qu√© y como usar Na√Øve Bayes?**\n",
    "\n",
    "Creemos que este m√©todo, pese a su simpleza, puede dar resultados interesantes en esta tarea. Como ejemplo consideremos el siguiente tweet:\n",
    "\n",
    "_Nearly halfway to **Christmas** üéÑ \n",
    "Let me know, what's your favorite thing about **winter**?\n",
    "Share this post with someone who celebrates **Christmas** all year round! üéÑ_\n",
    "\n",
    "Este tweet est√° relacionado con navidad, lo cual es evidente gracias a la presencia de ciertas palabras como: _christmas_ y _winter_. Como consecuencia, est√° muy propenso a que la clase en cuesti√≥n sea aquella del emoji _christmas_tree_, lo cual es efectivmente el caso. Si bien esto es menos claro para otros emoji, podemos generalizar esta idea y asumir que la clase del tweet estar√° dada por las palabras que lo componen. A su vez, cada palabra tendr√° una probabilidad de pertenecer a las clases en cuesti√≥n.\n",
    "\n",
    "El procedimiento para el clasificador ser√° el siguiente:\n",
    "\n",
    "``` \n",
    "Dado un par√°metro alfa y un vocabulario, ajustamos un clasificador Na√Øve Bayes en base al conjunto de entrenamiento. Luego testeados la calidad de su evaluaci√≥n con diferentes m√©tricas usando el conjuntos de prueba (test).\n",
    "```\n",
    "\n",
    "Una raz√≥n para el uso de este m√©todo es que los resultados de Na√Øve Bayes son altamente interpretables puesto a que a cada palabra se le asigna la probabilidad de pertenecer a las distintas clases. Esto nos da un eje extra de exploraci√≥n que usaremos del siguiente modo, dado un clasificador entrenado : \n",
    "\n",
    "```\n",
    "Para cada emoji, seleccionar k palabras con probabilidad m√°s alta de ser catalogadas con el emoji.\n",
    "```\n",
    "\n",
    "Otra manera de interpretar los resultados del clasificador es el siguiente: para cada palabra poseemos la probabilidad de pertenecer a alguna clase (emoji). Como tenemos 20 emojis (19 respectivamente), entonces esto nos dota de un vector 20-dimensional (resp. 19-d) a valores en [0,1]. Esto nos permite usar alguna t√©cnica de reducci√≥n de dimensionalidad para visualizar el espacio que se genera con tales representaciones. Para esta tarea elegimos umap, pues algunos de los miembros del grupo ya tienen vasta experiencia us√°ndola y afinando sus hiperpar√°metros. En resumen realizamos lo siguiente:\n",
    "\n",
    "```\n",
    "Para cada palabra del vocabulario, tomar su vector n-dimensional dado por la probabilidad de pertenecer a las n clases. Realizar una reducci√≥n de dimensi√≥n usando UMAP y proyectalos en el plano junto con el color de la clase m√°s probable y con tama√±o del punto dependiendo de cuan fuerte es la probabilidad de pertenecer a su clase m√°s probable. Realizar un an√°lisis cualitativo.\n",
    "```\n",
    "\n",
    "Para la implementaci√≥n del clasificador usaremos la librer√≠a scikitlearn. Un par√°metro a ajustar es el alpha. Este corresponde a la suavizaci√≥n de la verosimilitud, que est√° dada por la ecuaci√≥n siguiente:\n",
    "\n",
    "$$ \\theta_{y^i} = \\frac{N_{y^i}+\\alpha}{N_y+\\alpha n} $$\n",
    "\n",
    "Donde $N_{y^i}$ es el n√∫mero de veces que la palabra $i$ aparece en la clase $y$, y $N_y$ es el conteo total de palabras para la clase $y$. El valor $\\theta_{y^i}$ corresponde a la probabilidad de que una palabra $i$ aparezca en la clase (emoji) $y$.\n",
    "\n",
    "Por otro lado, la definici√≥n del vocabulario es importante a la hora de usar NB. Usamos tambi√©n la librer√≠a scikitlearn para esto. Esta posee un par√°metro min_df, que corresponde a la m√≠nima cantidad de ocurrencia que debe tener una palabra para que est√° sea tomada en cuenta en el clasificador. De este modo, un min_df = 1 tomara todas las palabras. Usar un min_df m√°s elevado nos permitir√° analizar solo aquellas palabras que suceden seguido y por ende que portar√°n m√°s informaci√≥n acerca de la pertenencia o no a una cierta clase.\n",
    "\n",
    "Realizaremos un grid search para ajustar ambos par√°metros en nuestro clasificador. Exploraremos los valores siguientes:\n",
    "\n",
    "$$\\alpha \\in \\[0.0,0.2,0.4,0.6,0.8,1.0\\]$$\n",
    "\n",
    "$$min\\textunderscore df \\in \\[ 1,2,3,4,5,6,7,8,9,10 \\] $$\n",
    "\n",
    "Y escogeremos el ganador en base a la m√©trica macro f1 para ser consistentes con el resultado de la competici√≥n SEMEVAL.\n",
    "\n",
    "```\n",
    "Para distintos valores de alpha y min_df, entrenar un clasificador NB y escoger aquel con mayor macro f1\n",
    "```\n",
    "\n",
    "**Por qu√© y como usar Transformers?**\n",
    "\n",
    "Transformers [2] es una arquitectura de redes neuronales que ha mostrado una enorme capacidad de modelar texto. Su uso se ha masificado y simplificado gracias a la existencia de bibliotecas como _transformers_, que ponen a libre disposici√≥n modelos pre-entrenados. Este punto es importante puesto a que entrenar un modelo de lenguaje robusto desde cero puede tomar tiempo y capacidad de c√≥mputo que van m√°s all√° de nuestras capacidades.\n",
    "\n",
    "Creemos que explorar su uso y compararlo con un clasificador como Na√Øve Bayes ser√° una buena manera de complementar los conocimientos adquiridos en el curso con recursos m√°s avanzados de inter√©s personal. Sin embargo nos centraremos en modelos pre-entrenados sin ajustar. En particular analizaremos los siguientes:\n",
    "- [BERTweet base (vinai)](https://huggingface.co/docs/transformers/model_doc/bertweet) [(3)](#ref3)\n",
    "- [BERTweet ajustado para predicci√≥n de emojis (CardiffNLP)](https://huggingface.co/cardiffnlp/bertweet-base-emoji)\n",
    "- [Twitter-roberta base (CardiffNLP)](https://huggingface.co/cardiffnlp/twitter-roberta-base) [(4)](#ref4)\n",
    "- [Twitter-roberta ajustado para predicci√≥n de emojis (CardiffNLP)](https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji)\n",
    "- [BETO base (DCC-UChile)](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased) [(5)](#ref5)\n",
    "\n",
    "Esta eleccion nos permitir√° comparar el efecto de hacer un ajuste a la tarea de predicci√≥n de emojis para dos modelos de transformers distintos en ingl√©s. Por otro lado, testearemos el uso de un modelo de lenguaje sin ajustar para los tweets en espa√±ol. Se har√° un an√°lisis de las predicciones consistente con el que usamos en Na√Øve Bayes, haciendo uso de las m√©tricas de clasificaci√≥n que provee la biblioteca _scikitlearn_.\n",
    "\n",
    "Por otro lado, se buscar√°n modos de interpretaci√≥n al an√°lizar algunas capas de atenci√≥n de los modelos. Para esto usaremos la herramienta open source [_bertviz_](https://github.com/jessevig/bertviz) [(6)](#ref6) que nos provee de una herramienta de visualizaci√≥n interactiva.\n",
    "\n",
    "Finalmente, cabe se√±alar que hay una conexi√≥n directa con la pregunta 2, que pretende analizar clusters usando distintas representaciones de los tweets. En efecto, los modelos de transformers anteriormente mencionados nos otorgan un vector por tweet que puede ser√° usado con este efecto. De este modo estaremos explorando tambi√©n el clasificador en cuesti√≥n a trav√©s del espacio sem√°ntico que define.\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "<a name=\"ref1\"></a>[1] Metsis, V., Androutsopoulos, I., & Paliouras, G. (2006, July). Spam filtering with naive bayes-which naive bayes?. In CEAS (Vol. 17, pp. 28-69).\n",
    "\n",
    "<a name=\"ref2\"></a>[2] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, ≈Å., & Polosukhin, I. (2017). Attention is All you Need. Advances in Neural Information Processing Systems, 30, 5998‚Äì6008. https://arxiv.org/abs/1706.03762\n",
    "\n",
    "<a name=\"ref3\"></a>[3] Nguyen, D. Q., Vu, T., & Nguyen, A. T. (2020, October). BERTweet: A pre-trained language model for English Tweets. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 9-14). https://aclanthology.org/2020.emnlp-demos.2.pdf\n",
    "\n",
    "<a name=\"ref4\"></a>[4] Barbieri, F., Camacho-Collados, J., Anke, L. E., & Neves, L. (2020, November). TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification. In Findings of the Association for Computational Linguistics: EMNLP 2020 (pp. 1644-1650). https://arxiv.org/pdf/2010.12421.pdf\n",
    "\n",
    "<a name=\"ref5\"></a>[5] Canete, J., Chaperon, G., Fuentes, R., Ho, J. H., Kang, H., & P√©rez, J. (2020). Spanish pre-trained bert model and evaluation data. Pml4dc at iclr, 2020, 2020. https://users.dcc.uchile.cl/~jperez/papers/pml4dc2020.pdf\n",
    "\n",
    "<a name=\"ref6\"></a>[6] Vig, J. (2019, July). A Multiscale Visualization of Attention in the Transformer Model. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations (pp. 37-42). https://aclanthology.org/P19-3007.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingl√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos un resumen de las m√©tricas usando los distintos clasificadores propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Este modelo est√° basado en el resultado del grid-search realizado en la secci√≥n corresondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from config import *\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "\n",
    "df_us_train['tokenized_text'] = df_us_train['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_us_test['tokenized_text'] = df_us_test['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_df = 10\n",
    "best_alpha = 0.2\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X_train_bow = vectorizer.fit_transform(df_us_train[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_us_test[\"tokenized_text\"])\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha)\n",
    "clf.fit(X_train_bow, df_us_train[\"label\"])\n",
    "\n",
    "y_pred_NB = clf.predict(X_test_bow)\n",
    "# print(\"M√©tricas de clasificaci√≥n usando Naive-Bayes\")\n",
    "# print(classification_report(df_us_test[\"label\"], y_pred_NB, target_names=df_us_mapping[\"emoji\"]))\n",
    "dict_NB = classification_report(df_us_test[\"label\"], y_pred_NB, target_names=df_us_mapping[\"emoji\"],output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos disponibles:\n",
      "\t- beto-emoji\n",
      "\t- twitter-roberta-base\n",
      "\t- bertweet-base\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "modelos = [f.replace('.pickle','') for f in listdir('resultados_test/')]\n",
    "print(\"Modelos disponibles:\")\n",
    "for m in modelos: print(\"\\t- \"+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_transformer = {}\n",
    "modelos.remove('beto-emoji')\n",
    "for m in modelos:\n",
    "    with open('resultados_test/{}.pickle'.format(m), 'rb') as handle:\n",
    "        list_pred = pickle.load(handle)\n",
    "        preds_transformer[m] = [str(i) for i in list_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "for m in modelos:\n",
    "    # print(\"M√©tricas de clasificaci√≥n usando Transformers-{}\".format(m))\n",
    "    # print(classification_report(df_us_test[\"label\"], preds_transformer[m], target_names=df_us_mapping[\"emoji\"]))\n",
    "    dict_results[m] = classification_report(df_us_test[\"label\"], preds_transformer[m], target_names=df_us_mapping[\"emoji\"],output_dict=True)\n",
    "\n",
    "dict_results['Naive-Bayes'] = dict_NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clfs = modelos + ['Naive-Bayes']\n",
    "cols = pd.MultiIndex.from_product([clfs, ['precission', 'recall', 'f1-score']])\n",
    "\n",
    "df_en = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">twitter-roberta-base</th>\n",
       "      <th colspan=\"3\" halign=\"left\">bertweet-base</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Naive-Bayes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>‚ù§</th>\n",
       "      <td>0.741124</td>\n",
       "      <td>0.862197</td>\n",
       "      <td>0.797089</td>\n",
       "      <td>0.812185</td>\n",
       "      <td>0.851824</td>\n",
       "      <td>0.831533</td>\n",
       "      <td>0.376373</td>\n",
       "      <td>0.482404</td>\n",
       "      <td>0.422843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòç</th>\n",
       "      <td>0.320503</td>\n",
       "      <td>0.443064</td>\n",
       "      <td>0.371948</td>\n",
       "      <td>0.327511</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.404249</td>\n",
       "      <td>0.260080</td>\n",
       "      <td>0.243064</td>\n",
       "      <td>0.251284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üì∑</th>\n",
       "      <td>0.303647</td>\n",
       "      <td>0.697626</td>\n",
       "      <td>0.423126</td>\n",
       "      <td>0.308837</td>\n",
       "      <td>0.710196</td>\n",
       "      <td>0.430476</td>\n",
       "      <td>0.143106</td>\n",
       "      <td>0.171788</td>\n",
       "      <td>0.156141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üá∫üá∏</th>\n",
       "      <td>0.722648</td>\n",
       "      <td>0.532068</td>\n",
       "      <td>0.612884</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>0.572088</td>\n",
       "      <td>0.672294</td>\n",
       "      <td>0.420067</td>\n",
       "      <td>0.517701</td>\n",
       "      <td>0.463801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚òÄ</th>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.622925</td>\n",
       "      <td>0.665260</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.583399</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.493281</td>\n",
       "      <td>0.311922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíú</th>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.228758</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>0.098592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòâ</th>\n",
       "      <td>0.161893</td>\n",
       "      <td>0.099541</td>\n",
       "      <td>0.123281</td>\n",
       "      <td>0.177606</td>\n",
       "      <td>0.070444</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.101747</td>\n",
       "      <td>0.075804</td>\n",
       "      <td>0.086880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíØ</th>\n",
       "      <td>0.337004</td>\n",
       "      <td>0.122990</td>\n",
       "      <td>0.180212</td>\n",
       "      <td>0.294221</td>\n",
       "      <td>0.270096</td>\n",
       "      <td>0.281643</td>\n",
       "      <td>0.208511</td>\n",
       "      <td>0.196945</td>\n",
       "      <td>0.202563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÅ</th>\n",
       "      <td>0.143443</td>\n",
       "      <td>0.030356</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.137681</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>0.072750</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.057242</td>\n",
       "      <td>0.073826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üéÑ</th>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.650188</td>\n",
       "      <td>0.783172</td>\n",
       "      <td>0.710511</td>\n",
       "      <td>0.566016</td>\n",
       "      <td>0.638188</td>\n",
       "      <td>0.599939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üì∏</th>\n",
       "      <td>0.473282</td>\n",
       "      <td>0.025652</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.394464</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>0.084257</td>\n",
       "      <td>0.263504</td>\n",
       "      <td>0.149359</td>\n",
       "      <td>0.190652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòú</th>\n",
       "      <td>0.101449</td>\n",
       "      <td>0.013861</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.065817</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.041864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÇ</th>\n",
       "      <td>0.452065</td>\n",
       "      <td>0.533524</td>\n",
       "      <td>0.489428</td>\n",
       "      <td>0.419958</td>\n",
       "      <td>0.663652</td>\n",
       "      <td>0.514403</td>\n",
       "      <td>0.328016</td>\n",
       "      <td>0.467137</td>\n",
       "      <td>0.385406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíï</th>\n",
       "      <td>0.275835</td>\n",
       "      <td>0.136276</td>\n",
       "      <td>0.182425</td>\n",
       "      <td>0.280054</td>\n",
       "      <td>0.238772</td>\n",
       "      <td>0.257770</td>\n",
       "      <td>0.181971</td>\n",
       "      <td>0.082917</td>\n",
       "      <td>0.113924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üî•</th>\n",
       "      <td>0.577502</td>\n",
       "      <td>0.526372</td>\n",
       "      <td>0.550753</td>\n",
       "      <td>0.743255</td>\n",
       "      <td>0.444833</td>\n",
       "      <td>0.556566</td>\n",
       "      <td>0.453903</td>\n",
       "      <td>0.449139</td>\n",
       "      <td>0.451508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòä</th>\n",
       "      <td>0.135502</td>\n",
       "      <td>0.265964</td>\n",
       "      <td>0.179535</td>\n",
       "      <td>0.157165</td>\n",
       "      <td>0.189709</td>\n",
       "      <td>0.171910</td>\n",
       "      <td>0.087386</td>\n",
       "      <td>0.071296</td>\n",
       "      <td>0.078525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòé</th>\n",
       "      <td>0.185644</td>\n",
       "      <td>0.225451</td>\n",
       "      <td>0.203620</td>\n",
       "      <td>0.214162</td>\n",
       "      <td>0.246994</td>\n",
       "      <td>0.229409</td>\n",
       "      <td>0.148607</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>0.132927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚ú®</th>\n",
       "      <td>0.306567</td>\n",
       "      <td>0.419425</td>\n",
       "      <td>0.354224</td>\n",
       "      <td>0.342202</td>\n",
       "      <td>0.407057</td>\n",
       "      <td>0.371823</td>\n",
       "      <td>0.267382</td>\n",
       "      <td>0.208439</td>\n",
       "      <td>0.234260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíô</th>\n",
       "      <td>0.239531</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.133271</td>\n",
       "      <td>0.340824</td>\n",
       "      <td>0.058748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.189633</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.128205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòò</th>\n",
       "      <td>0.181388</td>\n",
       "      <td>0.195745</td>\n",
       "      <td>0.188293</td>\n",
       "      <td>0.180762</td>\n",
       "      <td>0.238298</td>\n",
       "      <td>0.205580</td>\n",
       "      <td>0.128894</td>\n",
       "      <td>0.102128</td>\n",
       "      <td>0.113960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   twitter-roberta-base                     bertweet-base                      \\\n",
       "             precission    recall  f1-score    precission    recall  f1-score   \n",
       "‚ù§              0.741124  0.862197  0.797089      0.812185  0.851824  0.831533   \n",
       "üòç              0.320503  0.443064  0.371948      0.327511  0.527950  0.404249   \n",
       "üì∑              0.303647  0.697626  0.423126      0.308837  0.710196  0.430476   \n",
       "üá∫üá∏             0.722648  0.532068  0.612884      0.815058  0.572088  0.672294   \n",
       "‚òÄ              0.713768  0.622925  0.665260      0.745455  0.583399  0.654545   \n",
       "üíú              0.344262  0.018851  0.035745      0.230769  0.013465  0.025445   \n",
       "üòâ              0.161893  0.099541  0.123281      0.177606  0.070444  0.100877   \n",
       "üíØ              0.337004  0.122990  0.180212      0.294221  0.270096  0.281643   \n",
       "üòÅ              0.143443  0.030356  0.050107      0.137681  0.049436  0.072750   \n",
       "üéÑ              0.638710  0.768932  0.697797      0.650188  0.783172  0.710511   \n",
       "üì∏              0.473282  0.025652  0.048666      0.394464  0.047166  0.084257   \n",
       "üòú              0.101449  0.013861  0.024390      0.250000  0.000990  0.001972   \n",
       "üòÇ              0.452065  0.533524  0.489428      0.419958  0.663652  0.514403   \n",
       "üíï              0.275835  0.136276  0.182425      0.280054  0.238772  0.257770   \n",
       "üî•              0.577502  0.526372  0.550753      0.743255  0.444833  0.556566   \n",
       "üòä              0.135502  0.265964  0.179535      0.157165  0.189709  0.171910   \n",
       "üòé              0.185644  0.225451  0.203620      0.214162  0.246994  0.229409   \n",
       "‚ú®              0.306567  0.419425  0.354224      0.342202  0.407057  0.371823   \n",
       "üíô              0.239531  0.092318  0.133271      0.340824  0.058748  0.100220   \n",
       "üòò              0.181388  0.195745  0.188293      0.180762  0.238298  0.205580   \n",
       "\n",
       "   Naive-Bayes                      \n",
       "    precission    recall  f1-score  \n",
       "‚ù§     0.376373  0.482404  0.422843  \n",
       "üòç     0.260080  0.243064  0.251284  \n",
       "üì∑     0.143106  0.171788  0.156141  \n",
       "üá∫üá∏    0.420067  0.517701  0.463801  \n",
       "‚òÄ     0.228070  0.493281  0.311922  \n",
       "üíú     0.228758  0.062837  0.098592  \n",
       "üòâ     0.101747  0.075804  0.086880  \n",
       "üíØ     0.208511  0.196945  0.202563  \n",
       "üòÅ     0.103937  0.057242  0.073826  \n",
       "üéÑ     0.566016  0.638188  0.599939  \n",
       "üì∏     0.263504  0.149359  0.190652  \n",
       "üòú     0.065817  0.030693  0.041864  \n",
       "üòÇ     0.328016  0.467137  0.385406  \n",
       "üíï     0.181971  0.082917  0.113924  \n",
       "üî•     0.453903  0.449139  0.451508  \n",
       "üòä     0.087386  0.071296  0.078525  \n",
       "üòé     0.148607  0.120240  0.132927  \n",
       "‚ú®     0.267382  0.208439  0.234260  \n",
       "üíô     0.189633  0.096837  0.128205  \n",
       "üòò     0.128894  0.102128  0.113960  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lab in df_us_mapping[\"emoji\"].values:\n",
    "  values = []\n",
    "  for m in clfs:\n",
    "    values += list(dict_results[m][lab].values())[:3]\n",
    "  df_en.loc[lab] = values\n",
    "\n",
    "df_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen de resultados globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro f1</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>macro precision</th>\n",
       "      <th>weighted precision</th>\n",
       "      <th>macro recall</th>\n",
       "      <th>weighted recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>twitter-roberta-base</th>\n",
       "      <td>0.46024</td>\n",
       "      <td>0.315603</td>\n",
       "      <td>0.431739</td>\n",
       "      <td>0.367788</td>\n",
       "      <td>0.452797</td>\n",
       "      <td>0.331657</td>\n",
       "      <td>0.46024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertweet-base</th>\n",
       "      <td>0.48032</td>\n",
       "      <td>0.333912</td>\n",
       "      <td>0.456200</td>\n",
       "      <td>0.391118</td>\n",
       "      <td>0.486150</td>\n",
       "      <td>0.348414</td>\n",
       "      <td>0.48032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes</th>\n",
       "      <td>0.30642</td>\n",
       "      <td>0.226951</td>\n",
       "      <td>0.287651</td>\n",
       "      <td>0.237589</td>\n",
       "      <td>0.284859</td>\n",
       "      <td>0.235872</td>\n",
       "      <td>0.30642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      accuracy  macro f1  weighted f1  macro precision  \\\n",
       "twitter-roberta-base   0.46024  0.315603     0.431739         0.367788   \n",
       "bertweet-base          0.48032  0.333912     0.456200         0.391118   \n",
       "Naive-Bayes            0.30642  0.226951     0.287651         0.237589   \n",
       "\n",
       "                      weighted precision  macro recall  weighted recall  \n",
       "twitter-roberta-base            0.452797      0.331657          0.46024  \n",
       "bertweet-base                   0.486150      0.348414          0.48032  \n",
       "Naive-Bayes                     0.284859      0.235872          0.30642  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en_summary = pd.DataFrame(columns=['accuracy','macro f1','weighted f1','macro precision','weighted precision','macro recall','weighted recall'])\n",
    "\n",
    "for m in clfs:\n",
    "    values = []\n",
    "    values += [dict_results[m]['accuracy']]\n",
    "    values += [dict_results[m]['macro avg']['f1-score']] + [dict_results[m]['weighted avg']['f1-score']]\n",
    "    values += [dict_results[m]['macro avg']['precision']] + [dict_results[m]['weighted avg']['precision']]\n",
    "    values += [dict_results[m]['macro avg']['recall']] + [dict_results[m]['weighted avg']['recall']]\n",
    "    df_en_summary.loc[m] = values\n",
    "\n",
    "df_en_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espa√±ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_es_train['tokenized_text'] = df_es_train['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_es_test['tokenized_text'] = df_es_test['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_min_df = 5\n",
    "best_alpha = 0.2\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=best_min_df)\n",
    "X_train_bow_es = vectorizer.fit_transform(df_es_train[\"tokenized_text\"])\n",
    "X_test_bow_es = vectorizer.transform(df_es_test[\"tokenized_text\"])\n",
    "\n",
    "clf_es = MultinomialNB(alpha=best_alpha)\n",
    "clf_es.fit(X_train_bow_es, df_es_train[\"label\"])\n",
    "\n",
    "y_pred_NB_es = clf_es.predict(X_test_bow_es)\n",
    "\n",
    "dict_NB_es = classification_report(df_es_test[\"label\"], y_pred_NB_es, target_names=df_es_mapping[\"emoji\"],output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/camilo/miniconda3/envs/datamining_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "with open('resultados_test/beto-emoji.pickle', 'rb') as handle:\n",
    "    list_pred = pickle.load(handle)\n",
    "    preds_beto = [str(i) for i in list_pred]\n",
    "\n",
    "dict_results = {}\n",
    "dict_results['beto-emoji'] = classification_report(df_es_test[\"label\"], preds_beto, target_names=df_es_mapping[\"emoji\"],output_dict=True)\n",
    "\n",
    "dict_results['Naive-Bayes'] = dict_NB_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">beto-emoji</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Naive-Bayes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>‚ù§</th>\n",
       "      <td>0.387432</td>\n",
       "      <td>0.434844</td>\n",
       "      <td>0.409771</td>\n",
       "      <td>0.355032</td>\n",
       "      <td>0.387202</td>\n",
       "      <td>0.370420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòç</th>\n",
       "      <td>0.289291</td>\n",
       "      <td>0.385653</td>\n",
       "      <td>0.330594</td>\n",
       "      <td>0.281461</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.288288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòé</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.111628</td>\n",
       "      <td>0.130742</td>\n",
       "      <td>0.109145</td>\n",
       "      <td>0.118971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíô</th>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.021792</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>0.059369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíú</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.029787</td>\n",
       "      <td>0.045902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòú</th>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.077295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíû</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>‚ú®</th>\n",
       "      <td>0.260204</td>\n",
       "      <td>0.122596</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.218447</td>\n",
       "      <td>0.108173</td>\n",
       "      <td>0.144695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üé∂</th>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.235849</td>\n",
       "      <td>0.242131</td>\n",
       "      <td>0.133987</td>\n",
       "      <td>0.193396</td>\n",
       "      <td>0.158301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíò</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.031088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÅ</th>\n",
       "      <td>0.049296</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>0.039886</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.038278</td>\n",
       "      <td>0.043597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòÇ</th>\n",
       "      <td>0.509030</td>\n",
       "      <td>0.507672</td>\n",
       "      <td>0.508350</td>\n",
       "      <td>0.437433</td>\n",
       "      <td>0.545697</td>\n",
       "      <td>0.485604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üíï</th>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.059813</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.043011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòä</th>\n",
       "      <td>0.117126</td>\n",
       "      <td>0.231518</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.106129</td>\n",
       "      <td>0.138132</td>\n",
       "      <td>0.120034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòò</th>\n",
       "      <td>0.236041</td>\n",
       "      <td>0.234257</td>\n",
       "      <td>0.235145</td>\n",
       "      <td>0.197568</td>\n",
       "      <td>0.163728</td>\n",
       "      <td>0.179063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üí™</th>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.429967</td>\n",
       "      <td>0.395802</td>\n",
       "      <td>0.284987</td>\n",
       "      <td>0.364821</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üòâ</th>\n",
       "      <td>0.147002</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>0.156701</td>\n",
       "      <td>0.108040</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>0.101058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üëå</th>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.096154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>üá™üá∏</th>\n",
       "      <td>0.462830</td>\n",
       "      <td>0.455189</td>\n",
       "      <td>0.458977</td>\n",
       "      <td>0.293919</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.342520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beto-emoji                     Naive-Bayes                    \n",
       "   precission    recall  f1-score  precission    recall  f1-score\n",
       "‚ù§    0.387432  0.434844  0.409771    0.355032  0.387202  0.370420\n",
       "üòç    0.289291  0.385653  0.330594    0.281461  0.295455  0.288288\n",
       "üòé    0.117647  0.106195  0.111628    0.130742  0.109145  0.118971\n",
       "üíô    0.360000  0.021792  0.041096    0.126984  0.038741  0.059369\n",
       "üíú    0.000000  0.000000  0.000000    0.100000  0.029787  0.045902\n",
       "üòú    0.035461  0.018248  0.024096    0.114286  0.058394  0.077295\n",
       "üíû    0.000000  0.000000  0.000000    0.000000  0.000000  0.000000\n",
       "‚ú®    0.260204  0.122596  0.166667    0.218447  0.108173  0.144695\n",
       "üé∂    0.248756  0.235849  0.242131    0.133987  0.193396  0.158301\n",
       "üíò    0.000000  0.000000  0.000000    0.050847  0.022388  0.031088\n",
       "üòÅ    0.049296  0.033493  0.039886    0.050633  0.038278  0.043597\n",
       "üòÇ    0.509030  0.507672  0.508350    0.437433  0.545697  0.485604\n",
       "üíï    0.087432  0.045455  0.059813    0.046823  0.039773  0.043011\n",
       "üòä    0.117126  0.231518  0.155556    0.106129  0.138132  0.120034\n",
       "üòò    0.236041  0.234257  0.235145    0.197568  0.163728  0.179063\n",
       "üí™    0.366667  0.429967  0.395802    0.284987  0.364821  0.320000\n",
       "üòâ    0.147002  0.167770  0.156701    0.108040  0.094923  0.101058\n",
       "üëå    0.088608  0.155556  0.112903    0.084746  0.111111  0.096154\n",
       "üá™üá∏   0.462830  0.455189  0.458977    0.293919  0.410377  0.342520"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs_es = ['beto-emoji','Naive-Bayes']\n",
    "cols = pd.MultiIndex.from_product([clfs_es, ['precission', 'recall', 'f1-score']])\n",
    "\n",
    "df_es = pd.DataFrame(columns=cols)\n",
    "for lab in df_es_mapping[\"emoji\"].values:\n",
    "  values = []\n",
    "  for m in clfs_es:\n",
    "    values += list(dict_results[m][lab].values())[:3]\n",
    "  df_es.loc[lab] = values\n",
    "\n",
    "df_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro f1</th>\n",
       "      <th>weighted f1</th>\n",
       "      <th>macro precision</th>\n",
       "      <th>weighted precision</th>\n",
       "      <th>macro recall</th>\n",
       "      <th>weighted recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beto-emoji</th>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.181532</td>\n",
       "      <td>0.289702</td>\n",
       "      <td>0.198043</td>\n",
       "      <td>0.294545</td>\n",
       "      <td>0.188740</td>\n",
       "      <td>0.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes</th>\n",
       "      <td>0.2735</td>\n",
       "      <td>0.159230</td>\n",
       "      <td>0.258523</td>\n",
       "      <td>0.164319</td>\n",
       "      <td>0.252616</td>\n",
       "      <td>0.165764</td>\n",
       "      <td>0.2735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy  macro f1  weighted f1  macro precision  \\\n",
       "beto-emoji     0.3050  0.181532     0.289702         0.198043   \n",
       "Naive-Bayes    0.2735  0.159230     0.258523         0.164319   \n",
       "\n",
       "             weighted precision  macro recall  weighted recall  \n",
       "beto-emoji             0.294545      0.188740           0.3050  \n",
       "Naive-Bayes            0.252616      0.165764           0.2735  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_summary = pd.DataFrame(columns=['accuracy','macro f1','weighted f1','macro precision','weighted precision','macro recall','weighted recall'])\n",
    "\n",
    "for m in clfs_es:\n",
    "    values = []\n",
    "    values += [dict_results[m]['accuracy']]\n",
    "    values += [dict_results[m]['macro avg']['f1-score']] + [dict_results[m]['weighted avg']['f1-score']]\n",
    "    values += [dict_results[m]['macro avg']['precision']] + [dict_results[m]['weighted avg']['precision']]\n",
    "    values += [dict_results[m]['macro avg']['recall']] + [dict_results[m]['weighted avg']['recall']]\n",
    "    df_es_summary.loc[m] = values\n",
    "\n",
    "df_es_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('datamining_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
