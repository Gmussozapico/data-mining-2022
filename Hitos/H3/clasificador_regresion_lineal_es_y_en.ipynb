{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador regresion lineal - hito 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rc('axes', titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams.update({'lines.markeredgewidth': 1})\n",
    "plt.rcParams.update({'errorbar.capsize': 2})\n",
    "\n",
    "file_names = {\n",
    "    \"df_es_mapping\": \"../../Data/mapping/df_es_mapping.pickle\",\n",
    "    \"df_us_mapping\": \"../../Data/mapping/df_us_mapping.pickle\",\n",
    "    \n",
    "    \"df_es_test\": \"../../Data/test/df_es_test.pickle\",\n",
    "    \"df_us_test\": \"../../Data/test/df_us_test.pickle\",\n",
    "    \n",
    "    \"df_es_train\": \"../../Data/train/df_es_train.pickle\",\n",
    "    \"df_us_train\": \"../../Data/train/df_us_train.pickle\",\n",
    "    \n",
    "    \"df_es_trial\": \"../../Data/trial/df_es_trial.pickle\",\n",
    "    \"df_us_trial\": \"../../Data/trial/df_us_trial.pickle\",\n",
    "}\n",
    "\n",
    "# mas imports\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cargar sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_train = pickle.load(open(file_names[\"df_es_train\"], \"rb\"))\n",
    "df_es_trial = pickle.load(open(file_names[\"df_es_trial\"], \"rb\"))\n",
    "df_es_test = pickle.load(open(file_names[\"df_es_test\"], \"rb\"))\n",
    "\n",
    "df_us_train = pickle.load(open(file_names[\"df_us_train\"], \"rb\"))\n",
    "df_us_trial = pickle.load(open(file_names[\"df_us_trial\"], \"rb\"))\n",
    "df_us_test = pickle.load(open(file_names[\"df_us_test\"], \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_18</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0</td>\n",
       "      <td>en Pelham Parkway</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1</td>\n",
       "      <td>The calm before...... | w/ sofarsounds @user |...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>Just witnessed the great solar eclipse @ Tampa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3</td>\n",
       "      <td>This little lady is 26 weeks pregnant today! E...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4</td>\n",
       "      <td>Great road trip views! @ Shartlesville, Pennsy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label_0  label_1  \\\n",
       "0  test0                                  en Pelham Parkway        0        0   \n",
       "1  test1  The calm before...... | w/ sofarsounds @user |...        0        0   \n",
       "2  test2  Just witnessed the great solar eclipse @ Tampa...        0        0   \n",
       "3  test3  This little lady is 26 weeks pregnant today! E...        0        1   \n",
       "4  test4  Great road trip views! @ Shartlesville, Pennsy...        0        0   \n",
       "\n",
       "   label_10  label_11  label_12  label_13  label_14  label_15  ...  label_18  \\\n",
       "0         0         0         0         0         0         0  ...         0   \n",
       "1         1         0         0         0         0         0  ...         0   \n",
       "2         0         0         0         0         0         0  ...         0   \n",
       "3         0         0         0         0         0         0  ...         0   \n",
       "4         0         0         0         0         0         0  ...         0   \n",
       "\n",
       "   label_19  label_2  label_3  label_4  label_5  label_6  label_7  label_8  \\\n",
       "0         0        1        0        0        0        0        0        0   \n",
       "1         0        0        0        0        0        0        0        0   \n",
       "2         0        0        0        0        0        1        0        0   \n",
       "3         0        0        0        0        0        0        0        0   \n",
       "4         0        0        0        0        0        0        0        0   \n",
       "\n",
       "   label_9  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos el atributo multiclase categorico a variables binarias\n",
    "df_us_train2 = pd.get_dummies(df_us_train , columns = [\"label\"])\n",
    "df_us_trial2 = pd.get_dummies(df_us_trial , columns = [\"label\"])\n",
    "df_us_test2 = pd.get_dummies(df_us_test , columns = [\"label\"])\n",
    "#df_us_train2.head()\n",
    "df_us_test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pre-procesamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_19</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729044324441186304</td>\n",
       "      <td>Selfies for summatime @ Drexel University</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>selfies for summatime @ drexel university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>663834134037442560</td>\n",
       "      <td>Ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ready to be a bulldog with rasso #hailstate #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747449193350963200</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#scored my new #matcotools #slidehammer weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>691439672761925637</td>\n",
       "      <td>@user last night was so much fun @ Skyway Thea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@user last night was so much fun @ skyway theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758118895618109440</td>\n",
       "      <td>love beach days @ Manasquan Beach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>love beach days @ manasquan beach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  729044324441186304         Selfies for summatime @ Drexel University    \n",
       "1  663834134037442560  Ready to be a bulldog with rasso #hailstate #i...   \n",
       "2  747449193350963200  #scored my new #matcotools #slidehammer weight...   \n",
       "3  691439672761925637  @user last night was so much fun @ Skyway Thea...   \n",
       "4  758118895618109440                 love beach days @ Manasquan Beach    \n",
       "\n",
       "   label_0  label_1  label_10  label_11  label_12  label_13  label_14  \\\n",
       "0        0        0         0         0         1         0         0   \n",
       "1        0        0         0         0         0         0         1   \n",
       "2        0        0         0         0         0         0         0   \n",
       "3        0        0         0         0         0         0         0   \n",
       "4        0        0         0         0         1         0         0   \n",
       "\n",
       "   label_15  ...  label_19  label_2  label_3  label_4  label_5  label_6  \\\n",
       "0         0  ...         0        0        0        0        0        0   \n",
       "1         0  ...         0        0        0        0        0        0   \n",
       "2         0  ...         0        0        0        0        0        0   \n",
       "3         0  ...         0        0        0        0        0        1   \n",
       "4         0  ...         0        0        0        0        0        0   \n",
       "\n",
       "   label_7  label_8  label_9  \\\n",
       "0        0        0        0   \n",
       "1        0        0        0   \n",
       "2        0        0        0   \n",
       "3        0        0        0   \n",
       "4        0        0        0   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0          selfies for summatime @ drexel university  \n",
       "1  ready to be a bulldog with rasso #hailstate #i...  \n",
       "2  #scored my new #matcotools #slidehammer weight...  \n",
       "3  @user last night was so much fun @ skyway theatre  \n",
       "4                  love beach days @ manasquan beach  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_us_train2['tokenized_text'] = df_us_train2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))\n",
    "df_us_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_test2['tokenized_text'] = df_us_test2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10) # minima cantidad de veces que tiene que aparecer una palabra para ser considerado \n",
    "X_train_bow = vectorizer.fit_transform(df_us_train2[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_us_test2[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387292"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "X_train_bow.shape[0]\n",
    "#print(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en ingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos para el label 0\n",
    "%time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])\n",
    "\n",
    "#reg.predict(np.array([[3, 5]]))\n",
    "#array([16.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4337708335088303"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_train_bow, df_us_train2[\"label_17\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17777"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11338276  0.04996757  0.05058278 ...  0.0382701  -0.02656909\n",
      "  0.01485125]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = reg.predict(X_test_bow)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y pred no es binario, hay que darle un cuttoff donde aceptemos que el algoritmo acerto, eligimos el 50 % \n",
    "# de esta forma podemos usar metricas tipicas\n",
    "# c = corte\n",
    "\n",
    "# Entonces si el algoritmo predice con un número entre 0 y 1 aprox, \n",
    "def cutoff(lista, c):\n",
    "    i = 0\n",
    "    listanueva = []\n",
    "    for i in lista:\n",
    "        if i > c:\n",
    "            listanueva.append(1)\n",
    "        else:\n",
    "            listanueva.append(0)\n",
    "            \n",
    "    return listanueva       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label emoji                              name\n",
      "0      0     ❤                       _red_heart_\n",
      "1      1     😍     _smiling_face_with_hearteyes_\n",
      "2      2     😂          _face_with_tears_of_joy_\n",
      "3      3     💕                      _two_hearts_\n",
      "4      4     🔥                            _fire_\n",
      "5      5     😊  _smiling_face_with_smiling_eyes_\n",
      "6      6     😎    _smiling_face_with_sunglasses_\n",
      "7      7     ✨                        _sparkles_\n",
      "8      8     💙                      _blue_heart_\n",
      "9      9     😘             _face_blowing_a_kiss_\n",
      "10    10     📷                          _camera_\n",
      "11    11    🇺🇸                   _United_States_\n",
      "12    12     ☀                             _sun_\n",
      "13    13     💜                    _purple_heart_\n",
      "14    14     😉                    _winking_face_\n",
      "15    15     💯                  _hundred_points_\n",
      "16    16     😁  _beaming_face_with_smiling_eyes_\n",
      "17    17     🎄                  _Christmas_tree_\n",
      "18    18     📸               _camera_with_flash_\n",
      "19    19     😜        _winking_face_with_tongue_\n"
     ]
    }
   ],
   "source": [
    "df_us_mapping = pickle.load(open(file_names[\"df_us_mapping\"], \"rb\"))\n",
    "#df_us_mapping = df_us_mapping.sort_values('label')\n",
    "print(df_us_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9804392029280196, 'recall': 0.995108863894335, 'f1-score': 0.9877195677779484, 'support': 48455}, '1': {'precision': 0.7109756097560975, 'recall': 0.3773462783171521, 'f1-score': 0.49302325581395345, 'support': 1545}, 'accuracy': 0.97602, 'macro avg': {'precision': 0.8457074063420585, 'recall': 0.6862275711057435, 'f1-score': 0.740371411795951, 'support': 50000}, 'weighted avg': {'precision': 0.9721127778990071, 'recall': 0.97602, 'f1-score': 0.9724334517382609, 'support': 50000}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = reg.predict(X_test_bow)\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "y_predcut = cutoff(y_pred, Puntodecorte)\n",
    "\n",
    "print(classification_report(df_us_test2[\"label_17\"], y_predcut,output_dict = True ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.6235406602254429 | Recall = 0.1481982035856526 | f1-score = 0.2394789482330431 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.680140597539543 | Recall = 0.03781697366492402 | f1-score = 0.07165008099976858 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.7563370403767158 | Recall = 0.18687493811268444 | f1-score = 0.29970026003930367 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.7111111111111111 | Recall = 0.006402881296583463 | f1-score = 0.0126914877794854 | 💕 |\n",
      "None\n",
      "| 🔥 | Precisión = 0.764804469273743 | Recall = 0.2732262249276519 | f1-score = 0.40261745459892645 | 🔥 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8666666666666667 | Recall = 0.0028118747634239983 | f1-score = 0.005605562442731634 | 😊 |\n",
      "None\n",
      "| 😎 | Precisión = 0.7356948228882834 | Recall = 0.015764582238570676 | f1-score = 0.030867726077512286 | 😎 |\n",
      "None\n",
      "| ✨ | Precisión = 0.7250996015936255 | Recall = 0.039308855291576676 | f1-score = 0.07457488219627126 | ✨ |\n",
      "None\n",
      "| 💙 | Precisión = 0.7667560321715817 | Recall = 0.022587268993839837 | f1-score = 0.043881856540084384 | 💙 |\n",
      "None\n",
      "| 😘 | Precisión = 0.6116504854368932 | Recall = 0.004971983268881698 | f1-score = 0.00986378581493659 | 😘 |\n",
      "None\n",
      "| 📷 | Precisión = 0.7908496732026143 | Recall = 0.027848101265822784 | f1-score = 0.053801689639839924 | 📷 |\n",
      "None\n",
      "| 🇺🇸 | Precisión = 0.8563023308440824 | Recall = 0.32182343936043545 | f1-score = 0.4678246893738023 | 🇺🇸 |\n",
      "None\n",
      "| ☀ | Precisión = 0.7122108660570199 | Recall = 0.12591535901093676 | f1-score = 0.21399709067399386 | ☀ |\n",
      "None\n",
      "| 💜 | Precisión = 0.7435424354243543 | Recall = 0.040715296019397856 | f1-score = 0.07720306513409961 | 💜 |\n",
      "None\n",
      "| 😉 | Precisión = 0.7631578947368421 | Recall = 0.002713069510711947 | f1-score = 0.005406917125011654 | 😉 |\n",
      "None\n",
      "| 💯 | Precisión = 0.744413407821229 | Recall = 0.04965530091298677 | f1-score = 0.09310043668122271 | 💯 |\n",
      "None\n",
      "| 😁 | Precisión = 0.7843137254901961 | Recall = 0.003818980332251289 | f1-score = 0.0076009501187648465 | 😁 |\n",
      "None\n",
      "| 🎄 | Precisión = 0.7267377712394263 | Recall = 0.39642892968201426 | f1-score = 0.5130135652625429 | 🎄 |\n",
      "None\n",
      "| 📸 | Precisión = 0.7388535031847133 | Recall = 0.01081988620464509 | f1-score = 0.02132744989887847 | 📸 |\n",
      "None\n",
      "| 😜 | Precisión = 0.8333333333333334 | Recall = 0.001032844453625284 | f1-score = 0.0020631318341242004 | 😜 |\n",
      "None\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ahora vemos para cada label\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def metrica_clase1(y_real,y_pred,emoji):\n",
    "    Met_regresion_dict = classification_report(y_real, y_pred , output_dict = True )\n",
    "    return print(\"|\",df_us_mapping[\"emoji\"][emoji],\"|\",\"Precisión =\", Met_regresion_dict.get(\"1\").get(\"precision\"),\"|\", \"Recall =\" ,Met_regresion_dict.get(\"1\").get(\"recall\"),\"|\",\"f1-score =\" ,Met_regresion_dict.get(\"1\").get(\"f1-score\"),\"|\",df_us_mapping[\"emoji\"][emoji],\"|\")\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "def metrica_clase1_todos(train_bow,df_label):\n",
    "    Puntodecorte = 0.5\n",
    "    i = 0\n",
    "    f = df_label.shape[1]\n",
    "    # el for pasa de i = 0 hasta el 17 maoma\n",
    "    for i in range(f-3):\n",
    "        ###\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train_bow, df_label[str(\"label_\")+str(i)])\n",
    "        y_predcut = cutoff(reg.predict(train_bow), Puntodecorte)\n",
    "        print (metrica_clase1(df_label[str(\"label_\")+str(i)],y_predcut, i))\n",
    "        \n",
    "metrica_clase1_todos( X_train_bow , df_us_train2)       \n",
    "# AL UTILIZAR COMO PUNTO DE CORTE SOBRE EL 50% QUE SI\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se encuentran resultados mas altos de lo esperado en la precision, pero sin embargo el recall no es muy alto, el algoritmo de regresión lineal falla mucho en los falsos negativos ( Dice que no es el emoji, pero en realidad si es), a cambio de tener una precisión más alta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar el top de palabras, vamos a predecir y luego este valor de predicción va a corresponder al valor que la regresión le asocio al coeficiente de cada regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train_bow, df_us_train2[\"label_17\"])\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topPalabras(proba_matrix,emoji_id,k=5):\n",
    "    # retorna las palabras para las cuales el emoji en cuestión tiene mas probabilidad\n",
    "    prob = proba_matrix[:]  # mmm\n",
    "    ind = np.argpartition(prob,-k)[-k:]\n",
    "    val = prob[ind]\n",
    "    palabras = [vectorizer.inverse_transform([np.eye(1,vocab_length,k)[0]])[0][0] for k in ind]\n",
    "    return palabras, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎄\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['ohchristmastree', 'holidaze', 'litmas', 'xmas2015', 'xmas2016'],\n",
       " array([0.54584545, 0.57313968, 0.62446983, 0.7050567 , 0.76373461]))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 17\n",
    "map_emojis = df_us_mapping[\"label\"].values\n",
    "print(df_us_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "topPalabras(proba_matrix,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'sibabes': 0.804948529378079, 'snowwhite': 0.8203815604017426, '1luv': 0.9551082292107682, 'cityofbrotherlylove': 1.0276042069771996, 'kfodiaries': 0.9732962170496406}\n",
      "😍\n",
      "{'asada': 0.6821768010788973, 'gyu': 0.8567913547961459, 'enamorada': 0.764880037442025, 'eatgood': 0.8798387923167201, 'encanta': 0.6974620745801943}\n",
      "😂\n",
      "{'lmfaoooo': 0.7756739280963982, 'foolin': 0.7836170807026172, 'hysterical': 0.8031867993103163, 'postavideoyoucantexplain': 0.9092025087300106, 'clownin': 0.980526728422956}\n",
      "💕\n",
      "{'froomies': 0.4184682101946456, 'twinny': 0.5270839756126672, 'endorsement': 0.5009280482968419, 'honeybglam': 0.5480836741094768, 'bakers': 0.42597044968754366}\n",
      "🔥\n",
      "{'linkinmybio': 0.7315935943422897, 'fiya': 0.748510479195848, 'feeltheburn': 0.8444973901079282, 'instant_classic': 0.845625695616753, 'onfire': 0.9160725933546516}\n",
      "😊\n",
      "{'iah': 0.35770813114790895, 'allah': 0.3617374629968806, 'snowglobe': 0.38610150714220465, 'trigger': 0.46180553488716364, 'goodtime': 0.528529456916411}\n",
      "😎\n",
      "{'sunglasses': 0.5126454429948464, 'blackink': 0.5286790964118758, 'eyewear': 0.5434584721404843, 'raybans': 0.5520319238294865, 'digg': 0.7018821072245504}\n",
      "✨\n",
      "{'sparkle': 0.5078864907011988, 'hairbyme': 0.5264032318326115, 'mmxvi': 0.7225511419982117, 'hing': 1.0060537214014587, 'getonshimmur': 1.0163760125382462}\n",
      "💙\n",
      "{'bleedblue': 0.5626547318846709, 'leafs': 0.576885912936696, 'goroyals': 0.6973954292642884, 'itsaboy': 0.8644660797994382, 'foreverroyal': 0.5839502499197655}\n",
      "😘\n",
      "{'dirty30': 0.40593508808949835, 'besos': 0.4624433416137092, 'smooch': 0.7433733117058802, 'kissy': 0.5839960133957334, 'smooches': 0.7004524697601264}\n",
      "📷\n",
      "{'itsamazingoutthere': 0.657163770529224, 'conquer_la': 0.7277235711382505, 'acmecups': 0.8048222312349016, 'gdlfashion': 0.867047694685142, 'bvillain': 0.8659278688433318}\n",
      "🇺🇸\n",
      "{'holidayweekend': 0.6714730537801867, 'merica': 0.6816245743990132, 'weremember': 0.9377555005483801, 'madeintheusa': 0.707259173459025, 'happyfourth': 0.8736067226124485}\n",
      "☀\n",
      "{'floatin': 0.49781993475665387, 'sunshine': 0.5057195505238388, 'beachin': 0.5159139132987594, 'summerdays': 0.6019658374060001, 'photographer_serena': 0.9165463395683624}\n",
      "💜\n",
      "{'purplerain': 0.49781832643730695, 'endalz': 0.9051558304928538, 'purple': 0.510798755086326, 'tarleton': 0.5692994389083341, 'alzheimer': 0.6110837084904401}\n",
      "😉\n",
      "{'biased': 0.3531183468871711, 'phrase': 0.35464262088176274, 'womeninbusiness': 0.42862072015241254, 'backtowork': 0.4913070571230622, 'mividaesunatombola': 0.9969868506495924}\n",
      "💯\n",
      "{'rns': 0.6950447266941573, 't3t': 0.9111738165299632, 'keepit': 0.9490891453084365, 'eclecticeatery': 0.9980959849941287, 'childrenofthekorn': 0.9425514864079221}\n",
      "😁\n",
      "{'dentistry': 0.3537264665926751, 'podium': 0.35882469352312285, 'cheesin': 0.36385308847092396, 'thurgood': 0.457619239427909, 'djsty': 0.7692368005133594}\n",
      "🎄\n",
      "{'ohchristmastree': 0.5458454544210048, 'holidaze': 0.573139678861416, 'litmas': 0.6244698272628743, 'xmas2015': 0.7050566972648991, 'xmas2016': 0.763734613387404}\n",
      "📸\n",
      "{'mista': 0.3979439325666228, 'andaz': 0.4199207292743972, 'vagabond': 0.4402662810995539, 'banshee': 0.5627320549463201, 'mugshot': 0.47408596900504907}\n",
      "😜\n",
      "{'guessed': 0.3017456109296402, 'punny': 0.3831077915871773, 'dontjudgeme': 0.3260156091195437, 'warmup': 0.312748715535042, 'wacky': 0.31769729139819836}\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(20):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train_bow, df_us_train2[str(\"label_\")+str(i)])\n",
    "    proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "    print(df_us_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se encontro otro clasificador que puede relacionar cada palabra frecuente de un idioma a una probabilidad, si bien ya se habian encontrado probabilidades asociadas a palabras mediante el clasificador MultinomialNB, ahora se obtiene resultados mediante los coeficientes de la regresión lineal que relacionan a cada palabra con una probabilidad, lo siguiente es repetir el codigo para español."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_10</th>\n",
       "      <th>label_11</th>\n",
       "      <th>label_12</th>\n",
       "      <th>label_13</th>\n",
       "      <th>label_14</th>\n",
       "      <th>label_15</th>\n",
       "      <th>...</th>\n",
       "      <th>label_17</th>\n",
       "      <th>label_18</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "      <th>label_5</th>\n",
       "      <th>label_6</th>\n",
       "      <th>label_7</th>\n",
       "      <th>label_8</th>\n",
       "      <th>label_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test0</td>\n",
       "      <td>Buenos días desde Valencia en Comunidad Valenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test1</td>\n",
       "      <td>Anoche en la #prefería con @user ,mi prima eva...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test2</td>\n",
       "      <td>Porfavor llevarlas a reciclar,necesitamos más ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test3</td>\n",
       "      <td>El vecino roquero que todos queremos tener en ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test4</td>\n",
       "      <td>Es un placer contar con profesionales del sect...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  label_0  label_1  \\\n",
       "0  test0  Buenos días desde Valencia en Comunidad Valenc...        0        0   \n",
       "1  test1  Anoche en la #prefería con @user ,mi prima eva...        0        0   \n",
       "2  test2  Porfavor llevarlas a reciclar,necesitamos más ...        0        0   \n",
       "3  test3  El vecino roquero que todos queremos tener en ...        0        0   \n",
       "4  test4  Es un placer contar con profesionales del sect...        1        0   \n",
       "\n",
       "   label_10  label_11  label_12  label_13  label_14  label_15  ...  label_17  \\\n",
       "0         1         0         0         0         0         0  ...         0   \n",
       "1         0         0         0         0         0         0  ...         0   \n",
       "2         0         0         0         0         0         0  ...         0   \n",
       "3         0         0         0         0         0         0  ...         0   \n",
       "4         0         0         0         0         0         0  ...         0   \n",
       "\n",
       "   label_18  label_2  label_3  label_4  label_5  label_6  label_7  label_8  \\\n",
       "0         0        0        0        0        0        0        0        0   \n",
       "1         0        1        0        0        0        0        0        0   \n",
       "2         0        1        0        0        0        0        0        0   \n",
       "3         0        1        0        0        0        0        0        0   \n",
       "4         0        0        0        0        0        0        0        0   \n",
       "\n",
       "   label_9  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformamos el atributo multiclase categorico a variables binarias\n",
    "df_es_train2 = pd.get_dummies(df_es_train , columns = [\"label\"])\n",
    "df_es_trial2 = pd.get_dummies(df_es_trial , columns = [\"label\"])\n",
    "df_es_test2 = pd.get_dummies(df_es_test , columns = [\"label\"])\n",
    "#df_us_train2.head()\n",
    "df_es_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_es_train2['tokenized_text'] = df_es_train2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_test2['tokenized_text'] = df_es_test2['text'].str.lower().apply(lambda x: \" \".join(tt.tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10)   # Minimo de 10 ocurrencias para considerar una palabra\n",
    "X_train_bow = vectorizer.fit_transform(df_es_train2[\"tokenized_text\"])\n",
    "X_test_bow = vectorizer.transform(df_es_test2[\"tokenized_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>❤</td>\n",
       "      <td>_red_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>😍</td>\n",
       "      <td>_smiling_face_with_hearteyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>😂</td>\n",
       "      <td>_face_with_tears_of_joy_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>💕</td>\n",
       "      <td>_two_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>😊</td>\n",
       "      <td>_smiling_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>😘</td>\n",
       "      <td>_face_blowing_a_kiss_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>💪</td>\n",
       "      <td>_flexed_biceps_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>😉</td>\n",
       "      <td>_winking_face_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>👌</td>\n",
       "      <td>_OK_hand_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>🇪🇸</td>\n",
       "      <td>_Spain_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>😎</td>\n",
       "      <td>_smiling_face_with_sunglasses_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>💙</td>\n",
       "      <td>_blue_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>💜</td>\n",
       "      <td>_purple_heart_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>😜</td>\n",
       "      <td>_winking_face_with_tongue_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>💞</td>\n",
       "      <td>_revolving_hearts_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>✨</td>\n",
       "      <td>_sparkles_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>🎶</td>\n",
       "      <td>_musical_notes_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>💘</td>\n",
       "      <td>_heart_with_arrow_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>😁</td>\n",
       "      <td>_beaming_face_with_smiling_eyes_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label emoji                              name\n",
       "0      0     ❤                       _red_heart_\n",
       "1      1     😍     _smiling_face_with_hearteyes_\n",
       "2      2     😂          _face_with_tears_of_joy_\n",
       "3      3     💕                      _two_hearts_\n",
       "4      4     😊  _smiling_face_with_smiling_eyes_\n",
       "5      5     😘             _face_blowing_a_kiss_\n",
       "6      6     💪                   _flexed_biceps_\n",
       "7      7     😉                    _winking_face_\n",
       "8      8     👌                         _OK_hand_\n",
       "9      9    🇪🇸                           _Spain_\n",
       "10    10     😎    _smiling_face_with_sunglasses_\n",
       "11    11     💙                      _blue_heart_\n",
       "12    12     💜                    _purple_heart_\n",
       "13    13     😜        _winking_face_with_tongue_\n",
       "14    14     💞                _revolving_hearts_\n",
       "15    15     ✨                        _sparkles_\n",
       "16    16     🎶                   _musical_notes_\n",
       "17    17     💘                _heart_with_arrow_\n",
       "18    18     😁  _beaming_face_with_smiling_eyes_"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es_mapping = pickle.load(open(file_names[\"df_es_mapping\"], \"rb\"))\n",
    "df_es_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ❤ | Precisión = 0.640560593569662 | Recall = 0.09650975034157247 | f1-score = 0.1677461139896373 | ❤ |\n",
      "None\n",
      "| 😍 | Precisión = 0.6945454545454546 | Recall = 0.08355936652375535 | f1-score = 0.14917213370821616 | 😍 |\n",
      "None\n",
      "| 😂 | Precisión = 0.7568710359408034 | Recall = 0.13902912621359223 | f1-score = 0.23490813648293962 | 😂 |\n",
      "None\n",
      "| 💕 | Precisión = 0.7674418604651163 | Recall = 0.0061705310396409875 | f1-score = 0.012242626599888704 | 💕 |\n",
      "None\n",
      "| 😊 | Precisión = 0.8203125 | Recall = 0.019273127753303965 | f1-score = 0.03766140602582496 | 😊 |\n",
      "None\n",
      "| 😘 | Precisión = 0.8571428571428571 | Recall = 0.013114754098360656 | f1-score = 0.025834230355220672 | 😘 |\n",
      "None\n",
      "| 💪 | Precisión = 0.7531305903398927 | Recall = 0.13476312419974393 | f1-score = 0.2286179744773283 | 💪 |\n",
      "None\n",
      "| 😉 | Precisión = 0.8974358974358975 | Recall = 0.01122874558870709 | f1-score = 0.02217997465145754 | 😉 |\n",
      "None\n",
      "| 👌 | Precisión = 0.75 | Recall = 0.0020804438280166435 | f1-score = 0.004149377593360996 | 👌 |\n",
      "None\n",
      "| 🇪🇸 | Precisión = 0.8252788104089219 | Recall = 0.16104461371055495 | f1-score = 0.2694992412746586 | 🇪🇸 |\n",
      "None\n",
      "| 😎 | Precisión = 0.8431372549019608 | Recall = 0.016475095785440614 | f1-score = 0.03231867718902669 | 😎 |\n",
      "None\n",
      "| 💙 | Precisión = 0.7916666666666666 | Recall = 0.008061094611794654 | f1-score = 0.015959680806383873 | 💙 |\n",
      "None\n",
      "| 💜 | Precisión = 1.0 | Recall = 0.0027137042062415195 | f1-score = 0.005412719891745602 | 💜 |\n",
      "None\n",
      "| 😜 | Precisión = 0.8857142857142857 | Recall = 0.013543031891655745 | f1-score = 0.026678141135972458 | 😜 |\n",
      "None\n",
      "| 💞 | Precisión = 1.0 | Recall = 0.0004899559039686428 | f1-score = 0.0009794319294809011 | 💞 |\n",
      "None\n",
      "| ✨ | Precisión = 0.7333333333333333 | Recall = 0.016450648055832504 | f1-score = 0.03217942467089225 | ✨ |\n",
      "None\n",
      "| 🎶 | Precisión = 0.8411214953271028 | Recall = 0.04261363636363636 | f1-score = 0.08111762054979721 | 🎶 |\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 💘 | Precisión = 0.0 | Recall = 0.0 | f1-score = 0.0 | 💘 |\n",
      "None\n",
      "| 😁 | Precisión = 1.0 | Recall = 0.0027235587834770767 | f1-score = 0.005432322317790855 | 😁 |\n",
      "None\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Ahora vemos para cada label\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def metrica_clase1(y_real,y_pred,emoji):\n",
    "    Met_regresion_dict = classification_report(y_real, y_pred , output_dict = True )\n",
    "    return print(\"|\",df_es_mapping[\"emoji\"][emoji],\"|\",\"Precisión =\", Met_regresion_dict.get(\"1\").get(\"precision\"),\"|\", \"Recall =\" ,Met_regresion_dict.get(\"1\").get(\"recall\"),\"|\",\"f1-score =\" ,Met_regresion_dict.get(\"1\").get(\"f1-score\"),\"|\",df_es_mapping[\"emoji\"][emoji],\"|\")\n",
    "\n",
    "Puntodecorte = 0.5 # punto del cuttoff\n",
    "def metrica_clase1_todos(train_bow,df_label):\n",
    "    Puntodecorte = 0.5\n",
    "    i = 0\n",
    "    f = df_label.shape[1]\n",
    "    # el for pasa de i = 0 hasta el 17 maoma\n",
    "    for i in range(f-3):\n",
    "        ###\n",
    "        reg = LinearRegression()\n",
    "        reg.fit(train_bow, df_label[str(\"label_\")+str(i)])\n",
    "        y_predcut = cutoff(reg.predict(train_bow), Puntodecorte)\n",
    "        print (metrica_clase1(df_label[str(\"label_\")+str(i)],y_predcut, i))\n",
    "        \n",
    "metrica_clase1_todos( X_train_bow , df_es_train2)       \n",
    "# AL UTILIZAR COMO PUNTO DE CORTE SOBRE EL 50% QUE SI\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❤\n",
      "{'brindemos': 0.6171623483187451, 'fam': 0.6346323644888661, 'bachiller': 0.6495989749790456, 'valentín': 0.8008964010668764, 'ilovemadrid': 0.9422002659827386}\n",
      "😍\n",
      "{'felizañonuevo': 0.5784216021899539, 'familla': 0.5786858410584692, 'hermosos': 0.5849570548723055, 'james': 0.6252880697720704, 'preciosidad': 0.6134790639393111}\n",
      "😂\n",
      "{'jajajajajajajajaja': 0.7001654944377486, 'parto': 0.7445694185317469, 'aburrimiento': 0.774246266599665, 'meo': 0.8284886166645705, 'caretos': 0.7536431919924791}\n",
      "💕\n",
      "{'apuesto': 0.39092182611856946, 'imprescindibles': 0.3998922255897438, 'envío': 0.6174197792164663, 'vicálvaro': 0.4267764270658278, 'xeraco': 0.43886388576990565}\n",
      "😊\n",
      "{'invitación': 0.5004163027279447, 'perdiz': 0.5019288613362131, 'hashtags': 0.5279884467789383, 'comprando': 0.5787633982969738, 'esmorzant': 0.8017134414691671}\n",
      "😘\n",
      "{'besitos': 0.3598949919871568, 'ifach': 0.37693235544088693, 'besazo': 0.4808408450328213, 'rosita': 0.49784033978370773, 'besito': 0.49904464855369973}\n",
      "💪\n",
      "{'pretemporada': 0.5617289740634211, 'coraje': 0.580863397590506, 'aportodas': 0.586720833523348, 'gymlife': 0.6008821302040739, 'rendirme': 0.6096112211934601}\n",
      "😉\n",
      "{'hazlo': 0.33711370471360996, 'whatsapp650200641': 0.6001701836544764, 'cuentas': 0.34002042068232663, 'ideas': 0.37032435293741767, 'dedicada': 0.3736036279859942}\n",
      "👌\n",
      "{'campanario': 0.3022276231409026, 'muelle': 0.3161202678381744, 'ifach': 0.4153227707469443, 'rentan': 0.38592155405985085, 'páramo': 0.3453319343383163}\n",
      "🇪🇸\n",
      "{'periodistas': 0.48540268904762596, 'caídos': 0.5377499076298852, 'hispanidad': 0.5786484221316966, 'vivaespaña': 0.6881228292823591, 'north': 0.7119257513527579}\n",
      "😎\n",
      "{'malviviendo': 0.41080533776667305, 'peter': 0.4190286010420039, 'sunglasses': 0.5384796404617641, 'worldwide': 0.7979502968626467, 'peñón': 0.45563657163561966}\n",
      "💙\n",
      "{'azules': 0.29792655553860664, 'azul': 0.30227270769849873, 'bercial': 0.3315367410502464, 'blue': 0.3428975216651208, 'madrid2016': 0.5329058810272308}\n",
      "💜\n",
      "{'cañete': 0.2672800196246531, 'chozas': 0.31671704569561515, 'soporte': 0.3181863027132349, 'lozoya': 0.5375078930035204, 'esvedra': 0.3129222672523265}\n",
      "😜\n",
      "{'jejejeje': 0.40028156372352147, 'arahal': 0.40840090794779593, 'gayman': 0.4230699681200616, 'ricorico': 0.6009710777499211, 'movember': 0.4772180126205783}\n",
      "💞\n",
      "{'torredelcampo': 0.22708411033564085, 'mood': 0.22731269666914883, 'bae': 0.23189563922112735, 'alcosa': 0.2732297713184442, 'charcos': 0.23696136292045247}\n",
      "✨\n",
      "{'brillar': 0.32076253950476485, 'oscuridad': 0.3660211865501934, 'vibes': 0.35999369956618577, 'estrellas': 0.39657742368696064, 'chispa': 0.40056947540728416}\n",
      "🎶\n",
      "{'repita': 0.4384490509278387, 'comparación': 0.4652876953756747, 'mueran': 0.46609290722273233, 'espabila': 0.5051881230366945, 'cuéntame': 0.7264398250329305}\n",
      "💘\n",
      "{'busco': 0.2453596737073644, 'sector': 0.24816939753618314, 'discos': 0.2993235828603027, 'trucha': 0.3912313141740488, 'marchamalo': 0.2826151550888567}\n",
      "😁\n",
      "{'libres': 0.28652797511279254, 'campa': 0.287667984374749, 'major': 0.3041169882782342, 'instamoments': 0.3773201408427846, 'parra': 0.3986961345766038}\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vocab_length = X_train_bow.shape[1]\n",
    "#proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "\n",
    "for i in range(19):\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train_bow, df_es_train2[str(\"label_\")+str(i)])\n",
    "    proba_matrix = np.array([reg.predict(np.eye(1,vocab_length,k))[0] for k in range(vocab_length)])\n",
    "    print(df_es_mapping[\"emoji\"][int(map_emojis[i])])\n",
    "    pal, val = topPalabras(proba_matrix,i)\n",
    "    print(dict([(pal[j],val[j]) for j in range(len(pal))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se obtiene las palabras que son mas frecuentes según que emoji en español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
