{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\felip\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\felip\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "import pandas as pd \n",
    "from time import time  \n",
    "from collections import defaultdict \n",
    "import string \n",
    "import multiprocessing\n",
    "import os\n",
    "import gensim\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "\n",
    "# word2vec\n",
    "from gensim.models import Word2Vec, KeyedVectors, FastText\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "punctuation = string.punctuation + \"«»“”‘’…—\"\n",
    "\n",
    "stopwords_spanish = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt'\n",
    ").values\n",
    "stopwords_spanish = Counter(stopwords_spanish.flatten().tolist())\n",
    "\n",
    "stopwords_english = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt'\n",
    ").values\n",
    "stopwords_english = Counter(stopwords_english.flatten().tolist())\n",
    "\n",
    "def simple_tokenizer(doc, stopwords, lower=False):\n",
    "    if lower:\n",
    "        tokenized_doc = doc.translate(str.maketrans(\n",
    "            '', '', punctuation)).lower().split()\n",
    "\n",
    "    tokenized_doc = doc.translate(str.maketrans('', '', punctuation)).split()\n",
    "\n",
    "    tokenized_doc = [\n",
    "        token for token in tokenized_doc if token.lower() not in stopwords\n",
    "    ]\n",
    "    return tokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_from_df(df, stopwords, path):\n",
    "    emoji_w2v = Word2Vec(min_count=200,\n",
    "                          window=4,\n",
    "                          vector_size=200,\n",
    "                          sample=6e-5,\n",
    "                          alpha=0.03,\n",
    "                          min_alpha=0.0007,\n",
    "                          negative=20,\n",
    "                          workers=multiprocessing.cpu_count())\n",
    "\n",
    "    content = df[\"text\"]\n",
    "    cleaned_content = [simple_tokenizer(doc, stopwords=stopwords) for doc in content.values]\n",
    "    phrases = Phrases(cleaned_content, min_count=150, progress_per=5000) \n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = bigram[cleaned_content]\n",
    "\n",
    "    emoji_w2v.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "    t = time()\n",
    "    emoji_w2v.train(sentences, total_examples=emoji_w2v.corpus_count, epochs=15, report_delay=10)\n",
    "    print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "    emoji_w2v.init_sims(replace=True)\n",
    "\n",
    "    emoji_w2v.save(path)\n",
    "    return emoji_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"../../Data/train/df_us_train.pickle\"\n",
    "df_us_train = pickle.load(open(path, \"rb\"))\n",
    "\n",
    "path =  \"../../Data/train/df_es_train.pickle\"\n",
    "df_es_train = pickle.load(open(path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 12:32:26,482 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=200, alpha=0.03>', 'datetime': '2022-06-30T12:32:26.467519', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:32:31,705 : INFO : collecting all words and their counts\n",
      "2022-06-30 12:32:31,705 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2022-06-30 12:32:31,750 : INFO : PROGRESS: at sentence #5000, processed 29821 words and 36340 word types\n",
      "2022-06-30 12:32:31,799 : INFO : PROGRESS: at sentence #10000, processed 59723 words and 67133 word types\n",
      "2022-06-30 12:32:31,851 : INFO : PROGRESS: at sentence #15000, processed 89629 words and 96385 word types\n",
      "2022-06-30 12:32:31,901 : INFO : PROGRESS: at sentence #20000, processed 119889 words and 124696 word types\n",
      "2022-06-30 12:32:31,951 : INFO : PROGRESS: at sentence #25000, processed 149690 words and 151701 word types\n",
      "2022-06-30 12:32:32,005 : INFO : PROGRESS: at sentence #30000, processed 179903 words and 178348 word types\n",
      "2022-06-30 12:32:32,058 : INFO : PROGRESS: at sentence #35000, processed 209937 words and 204152 word types\n",
      "2022-06-30 12:32:32,105 : INFO : PROGRESS: at sentence #40000, processed 239768 words and 229387 word types\n",
      "2022-06-30 12:32:32,152 : INFO : PROGRESS: at sentence #45000, processed 269501 words and 254192 word types\n",
      "2022-06-30 12:32:32,197 : INFO : PROGRESS: at sentence #50000, processed 299491 words and 278555 word types\n",
      "2022-06-30 12:32:32,247 : INFO : PROGRESS: at sentence #55000, processed 329123 words and 302442 word types\n",
      "2022-06-30 12:32:32,294 : INFO : PROGRESS: at sentence #60000, processed 358815 words and 326024 word types\n",
      "2022-06-30 12:32:32,355 : INFO : PROGRESS: at sentence #65000, processed 388561 words and 349827 word types\n",
      "2022-06-30 12:32:32,399 : INFO : PROGRESS: at sentence #70000, processed 418452 words and 373000 word types\n",
      "2022-06-30 12:32:32,451 : INFO : PROGRESS: at sentence #75000, processed 448435 words and 396568 word types\n",
      "2022-06-30 12:32:32,499 : INFO : PROGRESS: at sentence #80000, processed 478447 words and 419738 word types\n",
      "2022-06-30 12:32:32,551 : INFO : PROGRESS: at sentence #85000, processed 508458 words and 442702 word types\n",
      "2022-06-30 12:32:32,604 : INFO : PROGRESS: at sentence #90000, processed 538325 words and 465368 word types\n",
      "2022-06-30 12:32:32,653 : INFO : PROGRESS: at sentence #95000, processed 568391 words and 488175 word types\n",
      "2022-06-30 12:32:32,697 : INFO : PROGRESS: at sentence #100000, processed 598149 words and 510646 word types\n",
      "2022-06-30 12:32:32,748 : INFO : PROGRESS: at sentence #105000, processed 628195 words and 532864 word types\n",
      "2022-06-30 12:32:32,795 : INFO : PROGRESS: at sentence #110000, processed 658152 words and 554901 word types\n",
      "2022-06-30 12:32:32,846 : INFO : PROGRESS: at sentence #115000, processed 687982 words and 576564 word types\n",
      "2022-06-30 12:32:32,897 : INFO : PROGRESS: at sentence #120000, processed 718002 words and 598212 word types\n",
      "2022-06-30 12:32:32,948 : INFO : PROGRESS: at sentence #125000, processed 747858 words and 619562 word types\n",
      "2022-06-30 12:32:32,999 : INFO : PROGRESS: at sentence #130000, processed 777833 words and 641094 word types\n",
      "2022-06-30 12:32:33,045 : INFO : PROGRESS: at sentence #135000, processed 807834 words and 662604 word types\n",
      "2022-06-30 12:32:33,100 : INFO : PROGRESS: at sentence #140000, processed 837667 words and 683937 word types\n",
      "2022-06-30 12:32:33,173 : INFO : PROGRESS: at sentence #145000, processed 867400 words and 704902 word types\n",
      "2022-06-30 12:32:33,220 : INFO : PROGRESS: at sentence #150000, processed 897281 words and 725859 word types\n",
      "2022-06-30 12:32:33,268 : INFO : PROGRESS: at sentence #155000, processed 927317 words and 747073 word types\n",
      "2022-06-30 12:32:33,312 : INFO : PROGRESS: at sentence #160000, processed 956963 words and 767471 word types\n",
      "2022-06-30 12:32:33,360 : INFO : PROGRESS: at sentence #165000, processed 987086 words and 788316 word types\n",
      "2022-06-30 12:32:33,410 : INFO : PROGRESS: at sentence #170000, processed 1017091 words and 809059 word types\n",
      "2022-06-30 12:32:33,458 : INFO : PROGRESS: at sentence #175000, processed 1046887 words and 829640 word types\n",
      "2022-06-30 12:32:33,510 : INFO : PROGRESS: at sentence #180000, processed 1076816 words and 850016 word types\n",
      "2022-06-30 12:32:33,566 : INFO : PROGRESS: at sentence #185000, processed 1106774 words and 870344 word types\n",
      "2022-06-30 12:32:33,619 : INFO : PROGRESS: at sentence #190000, processed 1136741 words and 890528 word types\n",
      "2022-06-30 12:32:33,674 : INFO : PROGRESS: at sentence #195000, processed 1166616 words and 910649 word types\n",
      "2022-06-30 12:32:33,733 : INFO : PROGRESS: at sentence #200000, processed 1196589 words and 930900 word types\n",
      "2022-06-30 12:32:33,792 : INFO : PROGRESS: at sentence #205000, processed 1226681 words and 951296 word types\n",
      "2022-06-30 12:32:33,843 : INFO : PROGRESS: at sentence #210000, processed 1256740 words and 971329 word types\n",
      "2022-06-30 12:32:33,900 : INFO : PROGRESS: at sentence #215000, processed 1286616 words and 991091 word types\n",
      "2022-06-30 12:32:33,959 : INFO : PROGRESS: at sentence #220000, processed 1316483 words and 1011057 word types\n",
      "2022-06-30 12:32:34,015 : INFO : PROGRESS: at sentence #225000, processed 1346385 words and 1030791 word types\n",
      "2022-06-30 12:32:34,070 : INFO : PROGRESS: at sentence #230000, processed 1376427 words and 1050757 word types\n",
      "2022-06-30 12:32:34,127 : INFO : PROGRESS: at sentence #235000, processed 1406495 words and 1070558 word types\n",
      "2022-06-30 12:32:34,181 : INFO : PROGRESS: at sentence #240000, processed 1436339 words and 1090205 word types\n",
      "2022-06-30 12:32:34,237 : INFO : PROGRESS: at sentence #245000, processed 1466282 words and 1109834 word types\n",
      "2022-06-30 12:32:34,297 : INFO : PROGRESS: at sentence #250000, processed 1496098 words and 1129510 word types\n",
      "2022-06-30 12:32:34,360 : INFO : PROGRESS: at sentence #255000, processed 1526021 words and 1148966 word types\n",
      "2022-06-30 12:32:34,417 : INFO : PROGRESS: at sentence #260000, processed 1555744 words and 1168249 word types\n",
      "2022-06-30 12:32:34,479 : INFO : PROGRESS: at sentence #265000, processed 1585756 words and 1187699 word types\n",
      "2022-06-30 12:32:34,534 : INFO : PROGRESS: at sentence #270000, processed 1615803 words and 1207385 word types\n",
      "2022-06-30 12:32:34,593 : INFO : PROGRESS: at sentence #275000, processed 1645378 words and 1226291 word types\n",
      "2022-06-30 12:32:34,647 : INFO : PROGRESS: at sentence #280000, processed 1675026 words and 1245223 word types\n",
      "2022-06-30 12:32:34,711 : INFO : PROGRESS: at sentence #285000, processed 1704866 words and 1263996 word types\n",
      "2022-06-30 12:32:34,764 : INFO : PROGRESS: at sentence #290000, processed 1734967 words and 1283113 word types\n",
      "2022-06-30 12:32:34,819 : INFO : PROGRESS: at sentence #295000, processed 1764809 words and 1302142 word types\n",
      "2022-06-30 12:32:34,874 : INFO : PROGRESS: at sentence #300000, processed 1794695 words and 1321038 word types\n",
      "2022-06-30 12:32:34,934 : INFO : PROGRESS: at sentence #305000, processed 1824734 words and 1340287 word types\n",
      "2022-06-30 12:32:34,990 : INFO : PROGRESS: at sentence #310000, processed 1854602 words and 1359084 word types\n",
      "2022-06-30 12:32:35,041 : INFO : PROGRESS: at sentence #315000, processed 1884377 words and 1377845 word types\n",
      "2022-06-30 12:32:35,095 : INFO : PROGRESS: at sentence #320000, processed 1914212 words and 1396458 word types\n",
      "2022-06-30 12:32:35,198 : INFO : PROGRESS: at sentence #325000, processed 1944071 words and 1415395 word types\n",
      "2022-06-30 12:32:35,250 : INFO : PROGRESS: at sentence #330000, processed 1974216 words and 1434132 word types\n",
      "2022-06-30 12:32:35,298 : INFO : PROGRESS: at sentence #335000, processed 2004053 words and 1452617 word types\n",
      "2022-06-30 12:32:35,347 : INFO : PROGRESS: at sentence #340000, processed 2033822 words and 1471132 word types\n",
      "2022-06-30 12:32:35,395 : INFO : PROGRESS: at sentence #345000, processed 2063591 words and 1489496 word types\n",
      "2022-06-30 12:32:35,450 : INFO : PROGRESS: at sentence #350000, processed 2093367 words and 1508074 word types\n",
      "2022-06-30 12:32:35,507 : INFO : PROGRESS: at sentence #355000, processed 2123593 words and 1526622 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 12:32:35,569 : INFO : PROGRESS: at sentence #360000, processed 2153424 words and 1545014 word types\n",
      "2022-06-30 12:32:35,626 : INFO : PROGRESS: at sentence #365000, processed 2183479 words and 1563543 word types\n",
      "2022-06-30 12:32:35,687 : INFO : PROGRESS: at sentence #370000, processed 2213300 words and 1581910 word types\n",
      "2022-06-30 12:32:35,741 : INFO : PROGRESS: at sentence #375000, processed 2243347 words and 1600485 word types\n",
      "2022-06-30 12:32:35,797 : INFO : PROGRESS: at sentence #380000, processed 2273268 words and 1619180 word types\n",
      "2022-06-30 12:32:35,852 : INFO : PROGRESS: at sentence #385000, processed 2303285 words and 1637550 word types\n",
      "2022-06-30 12:32:35,876 : INFO : collected 1645907 token types (unigram + bigrams) from a corpus of 2317037 words and 387292 sentences\n",
      "2022-06-30 12:32:35,877 : INFO : merged Phrases<1645907 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000>\n",
      "2022-06-30 12:32:35,878 : INFO : Phrases lifecycle event {'msg': 'built Phrases<1645907 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000> in 4.17s', 'datetime': '2022-06-30T12:32:35.878613', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:32:35,879 : INFO : exporting phrases from Phrases<1645907 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000>\n",
      "2022-06-30 12:32:40,251 : INFO : FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<146 phrases, min_count=150, threshold=10.0> from Phrases<1645907 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000> in 4.37s', 'datetime': '2022-06-30T12:32:40.251527', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:32:40,251 : INFO : collecting all words and their counts\n",
      "2022-06-30 12:32:40,252 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-06-30 12:32:40,368 : INFO : PROGRESS: at sentence #10000, processed 58349 words, keeping 22422 word types\n",
      "2022-06-30 12:32:40,485 : INFO : PROGRESS: at sentence #20000, processed 117077 words, keeping 37646 word types\n",
      "2022-06-30 12:32:40,597 : INFO : PROGRESS: at sentence #30000, processed 175685 words, keeping 50663 word types\n",
      "2022-06-30 12:32:40,707 : INFO : PROGRESS: at sentence #40000, processed 234156 words, keeping 62436 word types\n",
      "2022-06-30 12:32:40,822 : INFO : PROGRESS: at sentence #50000, processed 292455 words, keeping 73274 word types\n",
      "2022-06-30 12:32:40,937 : INFO : PROGRESS: at sentence #60000, processed 350387 words, keeping 83418 word types\n",
      "2022-06-30 12:32:41,051 : INFO : PROGRESS: at sentence #70000, processed 408598 words, keeping 93341 word types\n",
      "2022-06-30 12:32:41,176 : INFO : PROGRESS: at sentence #80000, processed 467232 words, keeping 103099 word types\n",
      "2022-06-30 12:32:41,287 : INFO : PROGRESS: at sentence #90000, processed 525688 words, keeping 112285 word types\n",
      "2022-06-30 12:32:41,402 : INFO : PROGRESS: at sentence #100000, processed 584047 words, keeping 121434 word types\n",
      "2022-06-30 12:32:41,518 : INFO : PROGRESS: at sentence #110000, processed 642585 words, keeping 130176 word types\n",
      "2022-06-30 12:32:41,633 : INFO : PROGRESS: at sentence #120000, processed 700957 words, keeping 138464 word types\n",
      "2022-06-30 12:32:41,748 : INFO : PROGRESS: at sentence #130000, processed 759261 words, keeping 146749 word types\n",
      "2022-06-30 12:32:41,866 : INFO : PROGRESS: at sentence #140000, processed 817692 words, keeping 154939 word types\n",
      "2022-06-30 12:32:41,984 : INFO : PROGRESS: at sentence #150000, processed 875883 words, keeping 162776 word types\n",
      "2022-06-30 12:32:42,096 : INFO : PROGRESS: at sentence #160000, processed 934175 words, keeping 170594 word types\n",
      "2022-06-30 12:32:42,213 : INFO : PROGRESS: at sentence #170000, processed 992815 words, keeping 178298 word types\n",
      "2022-06-30 12:32:42,333 : INFO : PROGRESS: at sentence #180000, processed 1051098 words, keeping 185899 word types\n",
      "2022-06-30 12:32:42,447 : INFO : PROGRESS: at sentence #190000, processed 1109612 words, keeping 193181 word types\n",
      "2022-06-30 12:32:42,561 : INFO : PROGRESS: at sentence #200000, processed 1168032 words, keeping 200459 word types\n",
      "2022-06-30 12:32:42,672 : INFO : PROGRESS: at sentence #210000, processed 1226751 words, keeping 207710 word types\n",
      "2022-06-30 12:32:42,783 : INFO : PROGRESS: at sentence #220000, processed 1285103 words, keeping 214831 word types\n",
      "2022-06-30 12:32:42,909 : INFO : PROGRESS: at sentence #230000, processed 1343618 words, keeping 221943 word types\n",
      "2022-06-30 12:32:43,035 : INFO : PROGRESS: at sentence #240000, processed 1402162 words, keeping 228800 word types\n",
      "2022-06-30 12:32:43,154 : INFO : PROGRESS: at sentence #250000, processed 1460544 words, keeping 235644 word types\n",
      "2022-06-30 12:32:43,274 : INFO : PROGRESS: at sentence #260000, processed 1518809 words, keeping 242409 word types\n",
      "2022-06-30 12:32:43,388 : INFO : PROGRESS: at sentence #270000, processed 1577458 words, keeping 249238 word types\n",
      "2022-06-30 12:32:43,503 : INFO : PROGRESS: at sentence #280000, processed 1635267 words, keeping 255791 word types\n",
      "2022-06-30 12:32:43,618 : INFO : PROGRESS: at sentence #290000, processed 1693710 words, keeping 262236 word types\n",
      "2022-06-30 12:32:43,735 : INFO : PROGRESS: at sentence #300000, processed 1752026 words, keeping 268791 word types\n",
      "2022-06-30 12:32:43,858 : INFO : PROGRESS: at sentence #310000, processed 1810606 words, keeping 275311 word types\n",
      "2022-06-30 12:32:43,978 : INFO : PROGRESS: at sentence #320000, processed 1868771 words, keeping 281665 word types\n",
      "2022-06-30 12:32:44,095 : INFO : PROGRESS: at sentence #330000, processed 1927387 words, keeping 288142 word types\n",
      "2022-06-30 12:32:44,216 : INFO : PROGRESS: at sentence #340000, processed 1985551 words, keeping 294418 word types\n",
      "2022-06-30 12:32:44,347 : INFO : PROGRESS: at sentence #350000, processed 2043633 words, keeping 300679 word types\n",
      "2022-06-30 12:32:44,475 : INFO : PROGRESS: at sentence #360000, processed 2102238 words, keeping 306859 word types\n",
      "2022-06-30 12:32:44,592 : INFO : PROGRESS: at sentence #370000, processed 2160702 words, keeping 313042 word types\n",
      "2022-06-30 12:32:44,722 : INFO : PROGRESS: at sentence #380000, processed 2219281 words, keeping 319242 word types\n",
      "2022-06-30 12:32:44,819 : INFO : collected 323625 word types from a corpus of 2262016 raw words and 387292 sentences\n",
      "2022-06-30 12:32:44,820 : INFO : Creating a fresh vocabulary\n",
      "2022-06-30 12:32:45,009 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=200 retains 1509 unique words (0.47% of original 323625, drops 322116)', 'datetime': '2022-06-30T12:32:45.009701', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:32:45,010 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=200 leaves 1108155 word corpus (48.99% of original 2262016, drops 1153861)', 'datetime': '2022-06-30T12:32:45.009701', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:32:45,025 : INFO : deleting the raw counts dictionary of 323625 items\n",
      "2022-06-30 12:32:45,033 : INFO : sample=6e-05 downsamples 1509 most-common words\n",
      "2022-06-30 12:32:45,034 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 387232.66999843885 word corpus (34.9%% of prior 1108155)', 'datetime': '2022-06-30T12:32:45.034588', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:32:45,059 : INFO : estimated required memory for 1509 words and 200 dimensions: 3168900 bytes\n",
      "2022-06-30 12:32:45,059 : INFO : resetting layer weights\n",
      "2022-06-30 12:32:45,063 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-30T12:32:45.063516', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 12:32:45,064 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2022-06-30T12:32:45.064509', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-06-30 12:32:46,095 : INFO : EPOCH 0 - PROGRESS: at 6.17% examples, 23719 words/s, in_qsize 14, out_qsize 1\n",
      "2022-06-30 12:32:50,471 : INFO : EPOCH 0: training on 2262016 raw words (387020 effective words) took 5.4s, 71810 effective words/s\n",
      "2022-06-30 12:32:51,759 : INFO : EPOCH 1 - PROGRESS: at 13.24% examples, 41055 words/s, in_qsize 15, out_qsize 0\n",
      "2022-06-30 12:32:55,915 : INFO : EPOCH 1: training on 2262016 raw words (387033 effective words) took 5.4s, 71616 effective words/s\n",
      "2022-06-30 12:32:56,945 : INFO : EPOCH 2 - PROGRESS: at 10.59% examples, 40048 words/s, in_qsize 15, out_qsize 0\n",
      "2022-06-30 12:33:01,117 : INFO : EPOCH 2: training on 2262016 raw words (387133 effective words) took 5.2s, 74624 effective words/s\n",
      "2022-06-30 12:33:02,185 : INFO : EPOCH 3 - PROGRESS: at 9.70% examples, 35647 words/s, in_qsize 16, out_qsize 0\n",
      "2022-06-30 12:33:06,479 : INFO : EPOCH 3: training on 2262016 raw words (386551 effective words) took 5.3s, 72336 effective words/s\n",
      "2022-06-30 12:33:07,570 : INFO : EPOCH 4 - PROGRESS: at 12.81% examples, 46011 words/s, in_qsize 15, out_qsize 0\n",
      "2022-06-30 12:33:11,630 : INFO : EPOCH 4: training on 2262016 raw words (387211 effective words) took 5.1s, 75416 effective words/s\n",
      "2022-06-30 12:33:12,726 : INFO : EPOCH 5 - PROGRESS: at 8.38% examples, 30511 words/s, in_qsize 9, out_qsize 7\n",
      "2022-06-30 12:33:17,084 : INFO : EPOCH 5: training on 2262016 raw words (386960 effective words) took 5.4s, 71332 effective words/s\n",
      "2022-06-30 12:33:18,125 : INFO : EPOCH 6 - PROGRESS: at 11.47% examples, 43053 words/s, in_qsize 9, out_qsize 3\n",
      "2022-06-30 12:33:22,510 : INFO : EPOCH 6: training on 2262016 raw words (387171 effective words) took 5.4s, 71511 effective words/s\n",
      "2022-06-30 12:33:23,854 : INFO : EPOCH 7 - PROGRESS: at 14.58% examples, 43382 words/s, in_qsize 12, out_qsize 7\n",
      "2022-06-30 12:33:27,390 : INFO : EPOCH 7: training on 2262016 raw words (388072 effective words) took 4.8s, 80139 effective words/s\n",
      "2022-06-30 12:33:28,425 : INFO : EPOCH 8 - PROGRESS: at 17.69% examples, 67394 words/s, in_qsize 0, out_qsize 1\n",
      "2022-06-30 12:33:32,604 : INFO : EPOCH 8: training on 2262016 raw words (386663 effective words) took 5.2s, 74518 effective words/s\n",
      "2022-06-30 12:33:33,700 : INFO : EPOCH 9 - PROGRESS: at 14.13% examples, 50651 words/s, in_qsize 14, out_qsize 1\n",
      "2022-06-30 12:33:37,726 : INFO : EPOCH 9: training on 2262016 raw words (386136 effective words) took 5.1s, 75683 effective words/s\n",
      "2022-06-30 12:33:38,760 : INFO : EPOCH 10 - PROGRESS: at 9.26% examples, 35493 words/s, in_qsize 11, out_qsize 5\n",
      "2022-06-30 12:33:43,067 : INFO : EPOCH 10: training on 2262016 raw words (387116 effective words) took 5.3s, 72796 effective words/s\n",
      "2022-06-30 12:33:44,129 : INFO : EPOCH 11 - PROGRESS: at 17.69% examples, 65579 words/s, in_qsize 9, out_qsize 0\n",
      "2022-06-30 12:33:48,100 : INFO : EPOCH 11: training on 2262016 raw words (387696 effective words) took 5.0s, 77341 effective words/s\n",
      "2022-06-30 12:33:49,352 : INFO : EPOCH 12 - PROGRESS: at 14.58% examples, 45997 words/s, in_qsize 11, out_qsize 0\n",
      "2022-06-30 12:33:53,467 : INFO : EPOCH 12: training on 2262016 raw words (387523 effective words) took 5.3s, 72501 effective words/s\n",
      "2022-06-30 12:33:54,519 : INFO : EPOCH 13 - PROGRESS: at 14.58% examples, 54757 words/s, in_qsize 14, out_qsize 1\n",
      "2022-06-30 12:33:58,223 : INFO : EPOCH 13: training on 2262016 raw words (387464 effective words) took 4.7s, 81831 effective words/s\n",
      "2022-06-30 12:33:59,249 : INFO : EPOCH 14 - PROGRESS: at 8.81% examples, 33827 words/s, in_qsize 16, out_qsize 0\n",
      "2022-06-30 12:34:03,320 : INFO : EPOCH 14: training on 2262016 raw words (386813 effective words) took 5.1s, 76180 effective words/s\n",
      "2022-06-30 12:34:03,321 : INFO : Word2Vec lifecycle event {'msg': 'training on 33930240 raw words (5806562 effective words) took 78.3s, 74199 effective words/s', 'datetime': '2022-06-30T12:34:03.321256', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "<ipython-input-4-c7be6c6a4d16>:23: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  emoji_w2v.init_sims(replace=True)\n",
      "2022-06-30 12:34:03,324 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2022-06-30 12:34:03,325 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'us_emoji_w2v.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-06-30T12:34:03.325241', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-06-30 12:34:03,326 : INFO : not storing attribute cum_table\n",
      "2022-06-30 12:34:03,331 : INFO : saved us_emoji_w2v.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.3 mins\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "us_emoji_w2v = word2vec_from_df(df_us_train, stopwords_english, \"us_emoji_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 12:34:03,484 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=200, alpha=0.03>', 'datetime': '2022-06-30T12:34:03.484815', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:34:04,387 : INFO : collecting all words and their counts\n",
      "2022-06-30 12:34:04,388 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2022-06-30 12:34:04,434 : INFO : PROGRESS: at sentence #5000, processed 28478 words and 33175 word types\n",
      "2022-06-30 12:34:04,481 : INFO : PROGRESS: at sentence #10000, processed 57196 words and 61335 word types\n",
      "2022-06-30 12:34:04,517 : INFO : PROGRESS: at sentence #15000, processed 85826 words and 86676 word types\n",
      "2022-06-30 12:34:04,561 : INFO : PROGRESS: at sentence #20000, processed 114762 words and 111512 word types\n",
      "2022-06-30 12:34:04,601 : INFO : PROGRESS: at sentence #25000, processed 143174 words and 134770 word types\n",
      "2022-06-30 12:34:04,645 : INFO : PROGRESS: at sentence #30000, processed 171920 words and 157712 word types\n",
      "2022-06-30 12:34:04,694 : INFO : PROGRESS: at sentence #35000, processed 200449 words and 179487 word types\n",
      "2022-06-30 12:34:04,735 : INFO : PROGRESS: at sentence #40000, processed 228971 words and 201048 word types\n",
      "2022-06-30 12:34:04,778 : INFO : PROGRESS: at sentence #45000, processed 257336 words and 222090 word types\n",
      "2022-06-30 12:34:04,817 : INFO : PROGRESS: at sentence #50000, processed 285838 words and 242561 word types\n",
      "2022-06-30 12:34:04,861 : INFO : PROGRESS: at sentence #55000, processed 314412 words and 263030 word types\n",
      "2022-06-30 12:34:04,904 : INFO : PROGRESS: at sentence #60000, processed 342750 words and 283149 word types\n",
      "2022-06-30 12:34:04,946 : INFO : PROGRESS: at sentence #65000, processed 371413 words and 303043 word types\n",
      "2022-06-30 12:34:04,991 : INFO : PROGRESS: at sentence #70000, processed 400015 words and 322618 word types\n",
      "2022-06-30 12:34:05,040 : INFO : PROGRESS: at sentence #75000, processed 428443 words and 342089 word types\n",
      "2022-06-30 12:34:05,095 : INFO : PROGRESS: at sentence #80000, processed 456784 words and 361046 word types\n",
      "2022-06-30 12:34:05,107 : INFO : collected 366195 token types (unigram + bigrams) from a corpus of 464331 words and 81326 sentences\n",
      "2022-06-30 12:34:05,107 : INFO : merged Phrases<366195 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000>\n",
      "2022-06-30 12:34:05,108 : INFO : Phrases lifecycle event {'msg': 'built Phrases<366195 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000> in 0.72s', 'datetime': '2022-06-30T12:34:05.108366', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:34:05,109 : INFO : exporting phrases from Phrases<366195 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000>\n",
      "2022-06-30 12:34:05,915 : INFO : FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<22 phrases, min_count=150, threshold=10.0> from Phrases<366195 vocab, min_count=150, threshold=10.0, max_vocab_size=40000000> in 0.80s', 'datetime': '2022-06-30T12:34:05.915021', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-06-30 12:34:05,915 : INFO : collecting all words and their counts\n",
      "2022-06-30 12:34:05,916 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-06-30 12:34:06,014 : INFO : PROGRESS: at sentence #10000, processed 56517 words, keeping 21094 word types\n",
      "2022-06-30 12:34:06,114 : INFO : PROGRESS: at sentence #20000, processed 113383 words, keeping 34555 word types\n",
      "2022-06-30 12:34:06,235 : INFO : PROGRESS: at sentence #30000, processed 169827 words, keeping 46101 word types\n",
      "2022-06-30 12:34:06,337 : INFO : PROGRESS: at sentence #40000, processed 226137 words, keeping 56149 word types\n",
      "2022-06-30 12:34:06,442 : INFO : PROGRESS: at sentence #50000, processed 282327 words, keeping 65358 word types\n",
      "2022-06-30 12:34:06,542 : INFO : PROGRESS: at sentence #60000, processed 338556 words, keeping 74274 word types\n",
      "2022-06-30 12:34:06,647 : INFO : PROGRESS: at sentence #70000, processed 395133 words, keeping 82460 word types\n",
      "2022-06-30 12:34:06,753 : INFO : PROGRESS: at sentence #80000, processed 451227 words, keeping 90393 word types\n",
      "2022-06-30 12:34:06,767 : INFO : collected 91458 word types from a corpus of 458686 raw words and 81326 sentences\n",
      "2022-06-30 12:34:06,768 : INFO : Creating a fresh vocabulary\n",
      "2022-06-30 12:34:06,811 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=200 retains 217 unique words (0.24% of original 91458, drops 91241)', 'datetime': '2022-06-30T12:34:06.811778', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:34:06,812 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=200 leaves 140118 word corpus (30.55% of original 458686, drops 318568)', 'datetime': '2022-06-30T12:34:06.812738', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:34:06,815 : INFO : deleting the raw counts dictionary of 91458 items\n",
      "2022-06-30 12:34:06,818 : INFO : sample=6e-05 downsamples 217 most-common words\n",
      "2022-06-30 12:34:06,819 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 15578.755480034048 word corpus (11.1%% of prior 140118)', 'datetime': '2022-06-30T12:34:06.819716', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-06-30 12:34:06,823 : INFO : estimated required memory for 217 words and 200 dimensions: 455700 bytes\n",
      "2022-06-30 12:34:06,824 : INFO : resetting layer weights\n",
      "2022-06-30 12:34:06,827 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-06-30T12:34:06.827711', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-06-30 12:34:06,828 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 217 vocabulary and 200 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2022-06-30T12:34:06.828692', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-06-30 12:34:07,746 : INFO : EPOCH 0: training on 458686 raw words (15613 effective words) took 0.9s, 17480 effective words/s\n",
      "2022-06-30 12:34:08,707 : INFO : EPOCH 1: training on 458686 raw words (15658 effective words) took 0.9s, 16670 effective words/s\n",
      "2022-06-30 12:34:09,546 : INFO : EPOCH 2: training on 458686 raw words (15705 effective words) took 0.8s, 19201 effective words/s\n",
      "2022-06-30 12:34:10,497 : INFO : EPOCH 3: training on 458686 raw words (15545 effective words) took 0.9s, 16633 effective words/s\n",
      "2022-06-30 12:34:11,475 : INFO : EPOCH 4: training on 458686 raw words (15640 effective words) took 1.0s, 16197 effective words/s\n",
      "2022-06-30 12:34:12,460 : INFO : EPOCH 5: training on 458686 raw words (15610 effective words) took 0.9s, 16525 effective words/s\n",
      "2022-06-30 12:34:13,354 : INFO : EPOCH 6: training on 458686 raw words (15609 effective words) took 0.9s, 17702 effective words/s\n",
      "2022-06-30 12:34:14,285 : INFO : EPOCH 7: training on 458686 raw words (15654 effective words) took 0.9s, 17109 effective words/s\n",
      "2022-06-30 12:34:15,204 : INFO : EPOCH 8: training on 458686 raw words (15609 effective words) took 0.9s, 17239 effective words/s\n",
      "2022-06-30 12:34:16,124 : INFO : EPOCH 9: training on 458686 raw words (15749 effective words) took 0.9s, 17573 effective words/s\n",
      "2022-06-30 12:34:16,960 : INFO : EPOCH 10: training on 458686 raw words (15586 effective words) took 0.8s, 18901 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 12:34:17,864 : INFO : EPOCH 11: training on 458686 raw words (15687 effective words) took 0.8s, 19312 effective words/s\n",
      "2022-06-30 12:34:18,824 : INFO : EPOCH 12: training on 458686 raw words (15695 effective words) took 0.9s, 16642 effective words/s\n",
      "2022-06-30 12:34:19,735 : INFO : EPOCH 13: training on 458686 raw words (15813 effective words) took 0.9s, 17650 effective words/s\n",
      "2022-06-30 12:34:20,636 : INFO : EPOCH 14: training on 458686 raw words (15496 effective words) took 0.9s, 17548 effective words/s\n",
      "2022-06-30 12:34:20,637 : INFO : Word2Vec lifecycle event {'msg': 'training on 6880290 raw words (234669 effective words) took 13.8s, 16995 effective words/s', 'datetime': '2022-06-30T12:34:20.637925', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "<ipython-input-4-c7be6c6a4d16>:23: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  emoji_w2v.init_sims(replace=True)\n",
      "2022-06-30 12:34:20,640 : WARNING : destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2022-06-30 12:34:20,641 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'es_emoji_w2v.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-06-30T12:34:20.641921', 'gensim': '4.2.0', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'saving'}\n",
      "2022-06-30 12:34:20,642 : INFO : not storing attribute cum_table\n",
      "2022-06-30 12:34:20,645 : INFO : saved es_emoji_w2v.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.23 mins\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "es_emoji_w2v = word2vec_from_df(df_es_train, stopwords_spanish, \"es_emoji_w2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding_from_w2v(doc, w2v):\n",
    "    pre_tokens = simple_tokenizer(doc, stopwords_spanish, lower=False)\n",
    "    sentence_vect = np.zeros(w2v.vector_size)\n",
    "    m = 0\n",
    "    for token in pre_tokens:\n",
    "        if token in w2v.wv:\n",
    "            sentence_vect += w2v.wv[token]\n",
    "            m += 1\n",
    "    sentence_vect *= 1/m if m>0 else 1\n",
    "    return sentence_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "us_train_w2v_sentence_embedding = pd.DataFrame(np.array(\n",
    "    [ sentence_embedding_from_w2v(doc, us_emoji_w2v) for doc in df_us_train[\"text\"]]\n",
    "))\n",
    "us_train_w2v_sentence_embedding[\"id\"] = df_us_train[\"id\"]\n",
    "us_train_w2v_sentence_embedding[\"label\"] = df_us_train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "es_train_w2v_sentence_embedding = pd.DataFrame(np.array(\n",
    "    [ sentence_embedding_from_w2v(doc, es_emoji_w2v) for doc in df_es_train[\"text\"]]\n",
    "))\n",
    "es_train_w2v_sentence_embedding[\"id\"] = df_es_train[\"id\"]\n",
    "es_train_w2v_sentence_embedding[\"label\"] = df_es_train[\"label\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
