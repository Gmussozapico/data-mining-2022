{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando transformers embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import listdir\n",
    "\n",
    "folder = 'bertweet_base_emoji/'\n",
    "\n",
    "target_set = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First token embedding\n",
    "\n",
    "Esta representación usa el vector contextualizado correspondiente al token '< s >', que es con el cual parten todas las secuencias. Este vector tiene la dimensionalidad de las capas escondidas del modelo (_hidden states_), que en el caso de BerTweet es 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_paths = [f for f in listdir(folder) if 'first_tok_embedding' in f and target_set in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de archivos disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vec_test_first_tok_embedding_16.npy',\n",
       " 'vec_test_first_tok_embedding_1.npy',\n",
       " 'vec_test_first_tok_embedding_6.npy',\n",
       " 'vec_test_first_tok_embedding_2.npy',\n",
       " 'vec_test_first_tok_embedding_15.npy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_paths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando uno de ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_test_first_tok_embedding_16.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2500, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(array_paths[0])\n",
    "array_ejemplo = np.load(folder+array_paths[0])\n",
    "array_ejemplo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dimensiones corresponden al número de vectores guardados y la dimensionalidad del modelo respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47501, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_array = np.concatenate([np.load(folder+array_paths[i]) for i in range(len(array_paths))])\n",
    "full_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto último corresponde a los vectores para cada uno de los elementos del set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum embedding\n",
    "\n",
    "Esta representación corresponde al promedio de cada uno de los embeddings contextuaizados. Embedding contextualizado corresponde al último estado oculto (_hidden state_) del modelo transformers para algún token del input. Es contextualizado puesto a que a lo largo de todas las capas del modelo esta representació ha ido cambiando al ser sometida a auto-atención, la cual la hace tomar en cuenta los otros tokens de input. Naturalmente estas representaciones tienen la dimensionalidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47501, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_paths = [f for f in listdir(folder) if 'sum_embedding' in f and target_set in f]\n",
    "\n",
    "full_array = np.concatenate([np.load(folder+array_paths[i]) for i in range(len(array_paths))])\n",
    "full_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logits embedding\n",
    "\n",
    "Este vector corresponde al output de la capa lineal que va sobre cada una de las capas de transformer. En este caso, esta capa ha sido entrenada para predecir el emoji de cada uno de los tweets. Son estos vectores los que posteriormente van a la capa softmax, que computa las probabilidades de pertenencia a cada clase. La dimensionalidad de estos vectores es igual a la cantidad de labels (emojis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47501, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_paths = [f for f in listdir(folder) if 'logits_embedding' in f and target_set in f]\n",
    "\n",
    "full_array = np.concatenate([np.load(folder+array_paths[i]) for i in range(len(array_paths))])\n",
    "full_array.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f20c33d1910a35bd4e57e72ae45c4ccb5c2a16c01a089293cb3a6910e8ec5b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
